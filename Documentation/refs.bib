
@article{liu_effects_nodate,
	title = {The Effects of Memory Replay in Reinforcement Learning},
	abstract = {Experience replay is a key technique behind many recent advances in deep reinforcement learning. Allowing the agent to learn from earlier memories can speed up learning and break undesirable temporal correlations. Despite its widespread application, very little is understood about the properties of experience replay. How does the amount of memory kept affect learning dynamics? Does it help to prioritize certain experiences? In this paper, we address these questions by formulating a dynamical systems {ODE} model of Q-learning with experience replay. We derive analytic solutions of the {ODE} for a simple setting. We show that even in this very simple setting, the amount of memory kept can substantially affect the agent‚Äôs performance‚Äîtoo much or too little memory both slow down learning. Moreover, we characterize regimes where prioritized replay harms the agent‚Äôs learning. We show that our analytic solutions have excellent agreement with experiments. Finally, we propose a simple algorithm for adaptively changing the memory buffer size which achieves consistently good empirical performance.},
	pages = {8},
	author = {Liu, Ruishan and Zou, James},
	langid = {english},
	file = {Liu and Zou - The Effects of Memory Replay in Reinforcement Lear.pdf:/home/lars/Zotero/storage/J6F2TEDB/Liu and Zou - The Effects of Memory Replay in Reinforcement Lear.pdf:application/pdf},
}

@online{james_answer_2019,
	title = {Answer to "How to "Merge" Sequential models in Keras 2.0?"},
	url = {https://stackoverflow.com/a/58152657},
	shorttitle = {Answer to "How to "Merge" Sequential models in Keras 2.0?},
	titleaddon = {Stack Overflow},
	author = {James},
	urldate = {2022-04-20},
	date = {2019-09-29},
	file = {Snapshot:/home/lars/Zotero/storage/TZN9CDY2/how-to-merge-sequential-models-in-keras-2-0.html:text/html},
}

@online{brownlee_loss_2019,
	title = {Loss and Loss Functions for Training Deep Learning Neural Networks},
	url = {https://machinelearningmastery.com/loss-and-loss-functions-for-training-deep-learning-neural-networks/},
	abstract = {Neural networks are trained using stochastic gradient descent and require that you choose a loss function when designing and configuring [‚Ä¶]},
	titleaddon = {Machine Learning Mastery},
	author = {Brownlee, Jason},
	urldate = {2022-04-17},
	date = {2019-01-27},
	langid = {american},
	file = {Snapshot:/home/lars/Zotero/storage/PCUXTMR2/loss-and-loss-functions-for-training-deep-learning-neural-networks.html:text/html},
}

@software{noauthor_tf-agents_2022,
	title = {{TF}-Agents: A reliable, scalable and easy to use {TensorFlow} library for Contextual Bandits and Reinforcement Learning.},
	rights = {Apache-2.0},
	url = {https://github.com/tensorflow/agents/blob/80c5f67f483ad24308c3a348b1c5a82780459c6b/docs/tutorials/1_dqn_tutorial.ipynb},
	shorttitle = {{TF}-Agents},
	abstract = {{TF}-Agents: A reliable, scalable and easy to use {TensorFlow} library for Contextual Bandits and Reinforcement Learning.},
	publisher = {tensorflow},
	urldate = {2022-04-15},
	date = {2022-04-15},
	note = {original-date: 2018-11-17T00:29:12Z},
}

@online{noauthor_environments_nodate,
	title = {Environments {\textbar} {TensorFlow} Agents},
	url = {https://www.tensorflow.org/agents/tutorials/2_environments_tutorial},
	titleaddon = {{TensorFlow}},
	urldate = {2022-04-15},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/7GKRGCRG/2_environments_tutorial.html:text/html},
}

@online{wang_deep_2021,
	title = {Deep Q-Learning Tutorial: {minDQN}},
	url = {https://towardsdatascience.com/deep-q-learning-tutorial-mindqn-2a4c855abffc},
	shorttitle = {Deep Q-Learning Tutorial},
	abstract = {A Practical Guide to Deep Q-Networks},
	titleaddon = {Medium},
	author = {Wang, Mike},
	urldate = {2022-04-15},
	date = {2021-10-03},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/PXU23T4R/deep-q-learning-tutorial-mindqn-2a4c855abffc.html:text/html},
}

@online{jagtap_understanding_2021,
	title = {Understanding Markov Decision Process ({MDP})},
	url = {https://towardsdatascience.com/understanding-the-markov-decision-process-mdp-8f838510f150},
	abstract = {Towards Training Better Reinforcement Learning Agents},
	titleaddon = {Medium},
	author = {Jagtap, Rohan},
	urldate = {2022-04-15},
	date = {2021-02-10},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/WR2MWAVF/understanding-the-markov-decision-process-mdp-8f838510f150.html:text/html},
}

@online{yoon_deep_2019,
	title = {Deep Deterministic Policy Gradients Explained},
	url = {https://towardsdatascience.com/deep-deterministic-policy-gradients-explained-2d94655a9b7b},
	abstract = {Reinforcement Learning in Continuous Action Spaces},
	titleaddon = {Medium},
	author = {Yoon, Chris},
	urldate = {2022-04-14},
	date = {2019-05-23},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/CSJDRD7P/deep-deterministic-policy-gradients-explained-2d94655a9b7b.html:text/html},
}

@online{unzueta_reinforcement_2022,
	title = {Reinforcement Learning: An Introduction},
	url = {https://towardsdatascience.com/reinforcement-learning-an-introduction-a8783f9ea993},
	shorttitle = {Reinforcement Learning},
	abstract = {An introduction to the fundamentals of Reinforcement Learning, all you need to know to get started},
	titleaddon = {Medium},
	author = {Unzueta, Diego},
	urldate = {2022-04-14},
	date = {2022-01-21},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/QSZQLYDW/reinforcement-learning-an-introduction-a8783f9ea993.html:text/html},
}

@article{graves_generating_2014,
	title = {Generating Sequences With Recurrent Neural Networks},
	url = {http://arxiv.org/abs/1308.0850},
	abstract = {This paper shows how Long Short-term Memory recurrent neural networks can be used to generate complex sequences with long-range structure, simply by predicting one data point at a time. The approach is demonstrated for text (where the data are discrete) and online handwriting (where the data are real-valued). It is then extended to handwriting synthesis by allowing the network to condition its predictions on a text sequence. The resulting system is able to generate highly realistic cursive handwriting in a wide variety of styles.},
	journaltitle = {{arXiv}:1308.0850 [cs]},
	author = {Graves, Alex},
	urldate = {2022-04-13},
	date = {2014-06-05},
	eprinttype = {arxiv},
	eprint = {1308.0850},
	keywords = {Computer Science - Computation and Language, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv Fulltext PDF:/home/lars/Zotero/storage/QW8EKZFV/Graves - 2014 - Generating Sequences With Recurrent Neural Network.pdf:application/pdf;arXiv.org Snapshot:/home/lars/Zotero/storage/3LLCCFVT/1308.html:text/html},
}

@article{graves_generating_2014-1,
	title = {Generating Sequences With Recurrent Neural Networks},
	url = {http://arxiv.org/abs/1308.0850},
	abstract = {This paper shows how Long Short-term Memory recurrent neural networks can be used to generate complex sequences with long-range structure, simply by predicting one data point at a time. The approach is demonstrated for text (where the data are discrete) and online handwriting (where the data are real-valued). It is then extended to handwriting synthesis by allowing the network to condition its predictions on a text sequence. The resulting system is able to generate highly realistic cursive handwriting in a wide variety of styles.},
	journaltitle = {{arXiv}:1308.0850 [cs]},
	author = {Graves, Alex},
	urldate = {2022-04-13},
	date = {2014-06-05},
	eprinttype = {arxiv},
	eprint = {1308.0850},
	keywords = {Computer Science - Computation and Language, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv Fulltext PDF:/home/lars/Zotero/storage/V6TE8XP4/Graves - 2014 - Generating Sequences With Recurrent Neural Network.pdf:application/pdf;arXiv.org Snapshot:/home/lars/Zotero/storage/N22N3MTL/1308.html:text/html},
}

@online{noauthor_keras-rl_nodate,
	title = {Keras-{RL} Documentation},
	url = {https://keras-rl.readthedocs.io/en/latest/search.html?q=dqnagent},
	urldate = {2022-04-13},
	file = {Keras-RL Documentation:/home/lars/Zotero/storage/2MLR78NX/search.html:text/html},
}

@online{noauthor_introduction_2021,
	title = {Introduction to Reinforcement Learning for Beginners},
	url = {https://www.analyticsvidhya.com/blog/2021/02/introduction-to-reinforcement-learning-for-beginners/},
	abstract = {Reinforcement Learning is definitely one of the evident research areas at present. This article is an introduction to reinforcement learning},
	titleaddon = {Analytics Vidhya},
	urldate = {2022-04-01},
	date = {2021-02-21},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/DN58US5V/introduction-to-reinforcement-learning-for-beginners.html:text/html},
}

@article{sutton_reinforcement_nodate,
	title = {Reinforcement Learning: An Introduction},
	pages = {352},
	author = {Sutton, Richard S and Barto, Andrew G},
	langid = {english},
	file = {Sutton und Barto - Reinforcement Learning An Introduction.pdf:/home/lars/Zotero/storage/X3EUZSVH/Sutton und Barto - Reinforcement Learning An Introduction.pdf:application/pdf},
}

@article{zhou_learning_2018,
	title = {Learning to Sketch with Deep Q Networks and Demonstrated Strokes},
	url = {http://arxiv.org/abs/1810.05977},
	abstract = {Doodling is a useful and common intelligent skill that people can learn and master. In this work, we propose a two-stage learning framework to teach a machine to doodle in a simulated painting environment via Stroke Demonstration and deep Q-learning ({SDQ}). The developed system, Doodle-{SDQ}, generates a sequence of pen actions to reproduce a reference drawing and mimics the behavior of human painters. In the first stage, it learns to draw simple strokes by imitating in supervised fashion from a set of strokeaction pairs collected from artist paintings. In the second stage, it is challenged to draw real and more complex doodles without ground truth actions; thus, it is trained with Qlearning. Our experiments confirm that (1) doodling can be learned without direct stepby- step action supervision and (2) pretraining with stroke demonstration via supervised learning is important to improve performance. We further show that Doodle-{SDQ} is effective at producing plausible drawings in different media types, including sketch and watercolor.},
	journaltitle = {{arXiv}:1810.05977 [cs]},
	author = {Zhou, Tao and Fang, Chen and Wang, Zhaowen and Yang, Jimei and Kim, Byungmoon and Chen, Zhili and Brandt, Jonathan and Terzopoulos, Demetri},
	urldate = {2022-03-31},
	date = {2018-10-14},
	eprinttype = {arxiv},
	eprint = {1810.05977},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/lars/Zotero/storage/QJR9FZBA/Zhou et al. - 2018 - Learning to Sketch with Deep Q Networks and Demons.pdf:application/pdf;arXiv.org Snapshot:/home/lars/Zotero/storage/Q6LZ876Z/1810.html:text/html},
}

@inproceedings{zheng_strokenet_2018,
	title = {{StrokeNet}: A Neural Painting Environment},
	url = {https://openreview.net/forum?id=HJxwDiActX},
	shorttitle = {{StrokeNet}},
	abstract = {{StrokeNet} is a novel architecture where the agent is trained to draw by strokes on a differentiable simulation of the environment, which could effectively exploit the power of back-propagation.},
	eventtitle = {International Conference on Learning Representations},
	author = {Zheng, Ningyuan and Jiang, Yifan and Huang, Dingjiang},
	urldate = {2022-03-31},
	date = {2018-09-27},
	langid = {english},
	file = {Full Text PDF:/home/lars/Zotero/storage/L3NKQJNQ/Zheng et al. - 2018 - StrokeNet A Neural Painting Environment.pdf:application/pdf;Snapshot:/home/lars/Zotero/storage/SGR3CCPH/forum.html:text/html},
}

@inproceedings{huang_learning_2019,
	location = {Seoul, Korea (South)},
	title = {Learning to Paint With Model-Based Deep Reinforcement Learning},
	isbn = {978-1-72814-803-8},
	url = {https://ieeexplore.ieee.org/document/9010329/},
	doi = {10.1109/ICCV.2019.00880},
	abstract = {We show how to teach machines to paint like human painters, who can use a small number of strokes to create fantastic paintings. By employing a neural renderer in model-based Deep Reinforcement Learning ({DRL}), our agents learn to determine the position and color of each stroke and make long-term plans to decompose texturerich images into strokes. Experiments demonstrate that excellent visual effects can be achieved using hundreds of strokes. The training process does not require the experience of human painters or stroke tracking data. The code is available at https://github.com/hzwer/ {ICCV}2019-{LearningToPaint}.},
	eventtitle = {2019 {IEEE}/{CVF} International Conference on Computer Vision ({ICCV})},
	pages = {8708--8717},
	booktitle = {2019 {IEEE}/{CVF} International Conference on Computer Vision ({ICCV})},
	publisher = {{IEEE}},
	author = {Huang, Zhewei and Zhou, Shuchang and Heng, Wen},
	urldate = {2022-03-31},
	date = {2019-10},
	langid = {english},
	file = {Huang et al. - 2019 - Learning to Paint With Model-Based Deep Reinforcem.pdf:/home/lars/Zotero/storage/XHDX6M3D/Huang et al. - 2019 - Learning to Paint With Model-Based Deep Reinforcem.pdf:application/pdf},
}

@online{noauthor_cs294-112_nodate,
	title = {{CS}294-112 Deep Reinforcement Learning Sp17 - {YouTube}},
	url = {https://www.youtube.com/playlist?list=PLkFD6_40KJIwTmSbCv9OVJB3YaO4sFwkX},
	urldate = {2022-03-27},
	file = {CS294-112 Deep Reinforcement Learning Sp17 - YouTube:/home/lars/Zotero/storage/D2S2XDWM/playlist.html:text/html},
}

@video{cognizant_ai_2019,
	title = {{AI} and Evolutionary Computation Experts Q\&A {\textbar} Jeff Clune {\textbar} Cognizant},
	url = {https://www.youtube.com/watch?app=desktop&v=0XCsNwvfJos&ab_channel=Cognizant},
	abstract = {Evolution has a key role to play as we push towards Artificial General Intelligence ({AGI}), mainly for three reasons. Firstly the neural evolution and the evolutionary algorithms communities have developed a lot of important ideas that have a role to play in general {AI} research whether or not they ultimately are used on an evolutionary backbone or they're hybridized with other ideas. Secondly evolutionary algorithms themselves may be a key technology for evolution in terms of having a part to play in the overall solution to {AI}. Third, to some extent these names for different fields are metaphorical and so if one thinks about evolution a little bit more broadly as the outer loop learning algorithm which is to say that we have something that kind of moves and learns across generations and then something that learns within a lifetime that outer loop which in nature is evolution and in machine learning sometimes is specifically an evolutionary algorithm or sometimes could be, say reinforcement learning algorithm that outer loop that is definitely going to be critical as we push towards {AGI} and some will call evolution, and some will fail to call it evolution. But at its heart, we're taking inspiration from natural evolution and evolutionary algorithms to do that outer loop activity, and that's essential. So in many different ways, evolutionary algorithms are going to be essential to our push towards {AI}, and we will increasingly see that the machine learning community is starting to take note and play with a lot of the ideas from evolution under its various interpretations and definitions. 

Learn more: https://cognizant.com/ai
Subscribe to this channel: https://cogniz.at/subscribeyt},
	author = {{Cognizant}},
	urldate = {2022-03-27},
	date = {2019-08-29},
}

@inproceedings{lin_dynamic_2019,
	title = {Dynamic Model Pruning with Feedback},
	url = {https://openreview.net/forum?id=SJem8lSFwB},
	abstract = {Deep neural networks often have millions of parameters. This can hinder their deployment to low-end devices, not only due to high memory requirements but also because of increased latency at...},
	eventtitle = {International Conference on Learning Representations},
	author = {Lin, Tao and Stich, Sebastian U. and Barba, Luis and Dmitriev, Daniil and Jaggi, Martin},
	urldate = {2022-03-27},
	date = {2019-09-25},
	langid = {english},
	file = {Full Text PDF:/home/lars/Zotero/storage/TCH3J44A/Lin et al. - 2019 - Dynamic Model Pruning with Feedback.pdf:application/pdf;Snapshot:/home/lars/Zotero/storage/WBVPI3WB/forum.html:text/html},
}

@software{palo_intelligent_2021,
	title = {Intelligent Control Techniques for Robot Manipulators.},
	url = {https://github.com/normandipalo/intelligent-control-techniques-for-robots/blob/af82092b6e5ce187f9c1912656d7dc45a23e119d/report.pdf},
	abstract = {An analysis of different intelligent control techniques (evolutionary alg., reinf. learn., neural networks) applied to robotic manipulators.},
	author = {Palo, Norman Di},
	urldate = {2022-03-27},
	date = {2021-09-25},
	note = {original-date: 2017-08-14T10:44:52Z},
}

@online{palo_making_2017,
	title = {Making a robot learn how to move, part 2 ‚Äì reinforcement learning in the real, wild world},
	url = {https://towardsdatascience.com/making-a-robot-learn-how-to-move-part-2-reinforcement-learning-in-the-real-wild-world-9427da7b9b21},
	abstract = {Tackling the bottlenecks of the physical world.},
	titleaddon = {Medium},
	author = {Palo, Norman Di},
	urldate = {2022-03-27},
	date = {2017-08-22},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/R49L3ETT/making-a-robot-learn-how-to-move-part-2-reinforcement-learning-in-the-real-wild-world-9427da7b9.html:text/html},
}

@online{palo_making_2017-1,
	title = {Making a robot learn how to move, part 1 ‚Äî Evolutionary algorithms},
	url = {https://towardsdatascience.com/making-a-robot-learn-how-to-move-part-1-evolutionary-algorithms-340f239c9cd2},
	abstract = {How nature inspires engineering.},
	titleaddon = {Medium},
	author = {Palo, Norman Di},
	urldate = {2022-03-27},
	date = {2017-08-14},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/MTBSRV6R/making-a-robot-learn-how-to-move-part-1-evolutionary-algorithms-340f239c9cd2.html:text/html},
}

@online{palo_making_2017-2,
	title = {Making a robot learn how to move ‚Äî Intro},
	url = {https://towardsdatascience.com/making-a-robot-learn-of-to-move-intro-2bcf3c3330df},
	abstract = {(or: where Artificial Intelligence meets Robotics)},
	titleaddon = {Medium},
	author = {Palo, Norman Di},
	urldate = {2022-03-27},
	date = {2017-08-14},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/LGYC25T9/making-a-robot-learn-of-to-move-intro-2bcf3c3330df.html:text/html},
}

@online{noauthor_introduction_nodate,
	title = {Introduction to {RL} and Deep Q Networks {\textbar} {TensorFlow} Agents},
	url = {https://www.tensorflow.org/agents/tutorials/0_intro_rl},
	titleaddon = {{TensorFlow}},
	urldate = {2022-03-22},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/TE9EVVW5/0_intro_rl.html:text/html},
}

@software{noauthor_tf-agents_2022-1,
	title = {{TF}-Agents: A reliable, scalable and easy to use {TensorFlow} library for Contextual Bandits and Reinforcement Learning.},
	rights = {Apache-2.0},
	url = {https://github.com/tensorflow/agents/blob/10ad6b054bb508adc5a8543ea4849d21f6cc6304/docs/tutorials/8_networks_tutorial.ipynb},
	shorttitle = {{TF}-Agents},
	abstract = {{TF}-Agents: A reliable, scalable and easy to use {TensorFlow} library for Contextual Bandits and Reinforcement Learning.},
	publisher = {tensorflow},
	urldate = {2022-04-21},
	date = {2022-04-19},
	note = {original-date: 2018-11-17T00:29:12Z},
}

@online{noauthor_networks_nodate,
	title = {Networks {\textbar} {TensorFlow} Agents},
	url = {https://www.tensorflow.org/agents/tutorials/8_networks_tutorial},
	titleaddon = {{TensorFlow}},
	urldate = {2022-04-21},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/J9MQ7WL5/8_networks_tutorial.html:text/html},
}

@online{noauthor_tf_agentsagentsddpgcritic_networkcriticnetwork_nodate,
	title = {tf\_agents.agents.ddpg.critic\_network.{CriticNetwork} {\textbar} {TensorFlow} Agents},
	url = {https://www.tensorflow.org/agents/api_docs/python/tf_agents/agents/ddpg/critic_network/CriticNetwork},
	abstract = {Creates a critic network.},
	titleaddon = {{TensorFlow}},
	urldate = {2022-04-21},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/X4SPADMX/CriticNetwork.html:text/html},
}

@online{noauthor_tf_agentsagentsddpgagent_nodate,
	title = {tf\_agents.agents.{DdpgAgent} {\textbar} {TensorFlow} Agents},
	url = {https://www.tensorflow.org/agents/api_docs/python/tf_agents/agents/DdpgAgent},
	abstract = {A {DDPG} Agent.},
	urldate = {2022-04-21},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/ZG65EZTC/DdpgAgent.html:text/html},
}

@article{nielsen_neural_2015,
	title = {Neural Networks and Deep Learning},
	url = {http://neuralnetworksanddeeplearning.com},
	author = {Nielsen, Michael A.},
	urldate = {2022-04-22},
	date = {2015},
	langid = {english},
	note = {Publisher: Determination Press},
	file = {Snapshot:/home/lars/Zotero/storage/GNB5Y64V/chap1.html:text/html},
}

@online{deshpande_adit_nodate,
	title = {Adit Deshpande ‚Äì Engineering at Forward {\textbar} {UCLA} {CS} '19},
	url = {https://adeshpande3.github.io/},
	abstract = {Engineering at Forward {\textbar} {UCLA} {CS} '19},
	author = {Deshpande, Adit},
	urldate = {2022-04-22},
	file = {Snapshot:/home/lars/Zotero/storage/W7GQGQ78/adeshpande3.github.io.html:text/html},
}

@software{padmaja-kulkarni_tfagents_examples_2021,
	title = {{TFAgents}\_examples},
	url = {https://github.com/padmaja-kulkarni/TFAgents_examples/blob/b06f3cf9aed20e87986eaacff4d1ab664d9de2e7/DDPG_pendulum.ipynb},
	author = {padmaja-kulkarni},
	urldate = {2022-04-22},
	date = {2021-05-04},
	note = {original-date: 2021-02-12T13:33:35Z},
}

@online{noauthor_python_nodate,
	title = {python error :Using Tensorflow Agents to realize reinforcement Learning {DQN}},
	url = {https://www.codestudyblog.com/cs2112pyc/1230143023.html},
	urldate = {2022-04-23},
	file = {python error \:Using Tensorflow Agents to realize reinforcement Learning DQN:/home/lars/Zotero/storage/N7HSBQ2U/1230143023.html:text/html},
}

@online{brownlee_why_2021,
	title = {Why Optimization Is Important in Machine Learning},
	url = {https://machinelearningmastery.com/why-optimization-is-important-in-machine-learning/},
	abstract = {Machine learning involves using an algorithm to learn and generalize from historical data in order to make predictions on new data. This problem can be described as approximating a function that maps examples of inputs to examples of outputs. Approximating a function can be solved by framing the problem as function optimization. This is where [‚Ä¶]},
	titleaddon = {Machine Learning Mastery},
	author = {Brownlee, Jason},
	urldate = {2022-07-20},
	date = {2021-06-01},
	langid = {american},
	file = {Snapshot:/home/lars/Zotero/storage/SG6SHWT9/why-optimization-is-important-in-machine-learning.html:text/html},
}

@online{noauthor_was_2018,
	title = {Was ist k√ºnstliche Intelligenz? {\textbar} {KI} Definition},
	url = {https://news.sap.com/germany/2018/03/was-ist-kuenstliche-intelligenz/},
	shorttitle = {Was ist k√ºnstliche Intelligenz?},
	abstract = {Welche Vorteile bringen K√ºnstliche Intelligenz ({KI}) und maschinelles Lernen? Von neuronalen Netzen √ºber Deep-Learning bis zu Gesch√§ftsszenarien. Lesen},
	titleaddon = {{SAP} News Center},
	urldate = {2022-06-29},
	date = {2018-03-20},
	langid = {german},
	file = {Snapshot:/home/lars/Zotero/storage/2L6UQ2NC/was-ist-kuenstliche-intelligenz.html:text/html},
}

@online{noauthor_was_nodate,
	title = {Was ist Unsupervised Learning (Un√ºberwachtes Lernen)?},
	url = {https://datasolut.com/wiki/unsupervised-learning/},
	abstract = {Unsupervised Learning im √úberblick: Lernen Sie, was un√ºberwachtes Lernen ist und welche Methoden und Beispiele es gibt.},
	titleaddon = {datasolut {GmbH}},
	urldate = {2022-06-25},
	langid = {german},
	file = {Snapshot:/home/lars/Zotero/storage/IWY3W85S/unsupervised-learning.html:text/html},
}

@online{arora_supervised_2020,
	title = {Supervised vs Unsupervised vs Reinforcement},
	url = {https://www.aitude.com/supervised-vs-unsupervised-vs-reinforcement/},
	abstract = {The amount of data generated in the world today is very huge. This data is generated not only by humans but also by smartphones, computers and other devices. Based on the kind of data available and a motive present, certainly, a programmer will choose how to train an algorithm using a specific learning model. Machine [‚Ä¶]},
	titleaddon = {{AITUDE}},
	author = {Arora, Surbhi},
	urldate = {2022-06-25},
	date = {2020-01-29},
	langid = {american},
	file = {Snapshot:/home/lars/Zotero/storage/NF67J7WH/supervised-vs-unsupervised-vs-reinforcement.html:text/html},
}

@online{noauthor_what_nodate,
	title = {What is Artificial Intelligence ({AI})? {\textbar} Glossary},
	url = {https://www.hpe.com/ch/de/what-is/artificial-intelligence.html},
	shorttitle = {What is Artificial Intelligence ({AI})?},
	abstract = {Artificial intelligence ({AI}) broadly refers to any human-like behavior displayed by a machine or system. In {AI}‚Äôs most basic form, computers are programmed to ‚Äúmimic‚Äù human behavior using extensive data from past examples of similar behavior. {\textbar} {HPE} Schweiz},
	urldate = {2022-06-21},
	langid = {german},
	file = {Snapshot:/home/lars/Zotero/storage/ZUMGS7LE/artificial-intelligence.html:text/html},
}

@online{noauthor_what_nodate-1,
	title = {What is Machine Learning? {\textbar} Glossary},
	url = {https://www.hpe.com/ch/de/what-is/machine-learning.html},
	shorttitle = {What is Machine Learning?},
	abstract = {Machine learning occurs when software is able to successfully predict and react to unfolding scenarios based on previous outcomes without human input. {\textbar} {HPE} Schweiz},
	urldate = {2022-06-21},
	langid = {german},
	file = {Snapshot:/home/lars/Zotero/storage/TEIDKBFJ/machine-learning.html:text/html},
}

@online{noauthor_duden_nodate,
	title = {Duden {\textbar} Roboter {\textbar} Rechtschreibung, Bedeutung, Definition, Herkunft},
	url = {https://www.duden.de/rechtschreibung/Roboter},
	abstract = {Definition, Rechtschreibung, Synonyme und Grammatik von 'Roboter' auf Duden online nachschlagen. W√∂rterbuch der deutschen Sprache.},
	urldate = {2022-06-19},
	langid = {german},
	file = {Snapshot:/home/lars/Zotero/storage/H72HBNPD/Roboter.html:text/html},
}

@online{ai_brief_2019,
	title = {A brief overview of Imitation Learning},
	url = {https://smartlabai.medium.com/a-brief-overview-of-imitation-learning-8a8a75c44a9c},
	abstract = {Author: Zolt√°n L≈ërincz},
	titleaddon = {Medium},
	author = {{AI}, {SmartLab}},
	urldate = {2022-06-19},
	date = {2019-09-19},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/QH6ML9HQ/a-brief-overview-of-imitation-learning-8a8a75c44a9c.html:text/html},
}

@online{noauthor_physics_nodate,
	title = {physics of drawing},
	url = {https://prezi.com/ggratirdoenz/physics-of-drawing/},
	abstract = {2nd law : force = mass x acceleration 3rd law:For every action there is an equal and opposite reaction. this is applied when shading a picture or coloring it black-white. this is because of the amount of force you apply to the pencil depends on the darkness/lightness. When you're},
	titleaddon = {prezi.com},
	urldate = {2022-06-19},
	langid = {german},
	file = {Snapshot:/home/lars/Zotero/storage/JVA6B33A/physics-of-drawing.html:text/html},
}

@online{noauthor_deep_2019,
	title = {Deep Learning vs Machine Learning - Was ist der Unterschied?},
	url = {https://it-talents.de/it-wissen/programmieren/deep-learning-vs-machine-learning-was-ist-der-unterschied/},
	abstract = {Die Fortschritte im Bereich der k√ºnstlichen Intelligenz sind f√ºr viele Zeitgenossen eher unverst√§ndlich. Doch im Grunde l√§uft es auf zwei Konzepte hinaus, von denen Du‚Ä¶},
	titleaddon = {{IT}-Talents.de},
	urldate = {2022-06-18},
	date = {2019-04-03},
	langid = {german},
	file = {Snapshot:/home/lars/Zotero/storage/VG2VMKVG/deep-learning-vs-machine-learning-was-ist-der-unterschied.html:text/html},
}

@article{nielsen_neural_2015-1,
	title = {Neural Networks and Deep Learning},
	url = {http://neuralnetworksanddeeplearning.com},
	author = {Nielsen, Michael A.},
	urldate = {2022-05-04},
	date = {2015},
	langid = {english},
	note = {Publisher: Determination Press},
	file = {Snapshot:/home/lars/Zotero/storage/L3IJI8YR/chap1.html:text/html},
}

@online{deshpande_beginners_nodate,
	title = {A Beginner's Guide To Understanding Convolutional Neural Networks Part 2},
	url = {https://adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks-Part-2/},
	abstract = {{ReLUs}, Pooling, Dropout...(aka The Fun Stuff)},
	author = {Deshpande, Adit},
	urldate = {2022-04-28},
	file = {Snapshot:/home/lars/Zotero/storage/M2VEVA57/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks-Part-2.html:text/html},
}

@online{noauthor_deep_2019-1,
	title = {Deep Q-Learning {\textbar} An Introduction To Deep Reinforcement Learning},
	url = {https://www.analyticsvidhya.com/blog/2019/04/introduction-deep-q-learning-python/},
	abstract = {An Introduction To Deep Reinforcement Learning. Learn about deep Q-learning, and build a deep Q-learning model in Python using keras and gym.},
	titleaddon = {Analytics Vidhya},
	urldate = {2022-04-25},
	date = {2019-04-18},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/X9KIV4CV/introduction-deep-q-learning-python.html:text/html},
}

@online{ad_how_2018,
	title = {How exactly to compute Deep Q-Learning Loss Function?},
	url = {https://stats.stackexchange.com/q/249355},
	titleaddon = {Cross Validated},
	author = {A.D},
	urldate = {2022-04-25},
	date = {2018-07-06},
}

@online{ad_answer_2016,
	title = {Answer to "How exactly to compute Deep Q-Learning Loss Function?"},
	url = {https://stats.stackexchange.com/a/250005},
	shorttitle = {Answer to "How exactly to compute Deep Q-Learning Loss Function?},
	titleaddon = {Cross Validated},
	author = {A.D},
	urldate = {2022-04-25},
	date = {2016-12-06},
	file = {Snapshot:/home/lars/Zotero/storage/Y3JNFQX9/how-exactly-to-compute-deep-q-learning-loss-function.html:text/html},
}

@online{ad_how_2018-1,
	title = {How exactly to compute Deep Q-Learning Loss Function?},
	url = {https://stats.stackexchange.com/q/249355},
	titleaddon = {Cross Validated},
	author = {A.D},
	urldate = {2022-04-25},
	date = {2018-07-06},
	file = {Snapshot:/home/lars/Zotero/storage/LVRJYBI2/how-exactly-to-compute-deep-q-learning-loss-function.html:text/html},
}

@inreference{noauthor_git_2021,
	title = {Git},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=Git&oldid=1062380476},
	abstract = {Git () is software for tracking changes in any set of files, usually used for coordinating work among programmers collaboratively developing source code during software development. Its goals include speed, data integrity, and support for distributed, non-linear workflows (thousands of parallel branches running on different systems).Git was created by Linus Torvalds in 2005 for development of the Linux kernel, with other kernel developers contributing to its initial development. Since 2005, Junio Hamano has been the core maintainer. As with most other distributed version control systems, and unlike most client‚Äìserver systems, every Git directory on every computer is a full-fledged repository with complete history and full version-tracking abilities, independent of network access or a central server. Git is free and open-source software distributed under the {GPL}-2.0-only license.},
	booktitle = {Wikipedia},
	urldate = {2021-12-30},
	date = {2021-12-28},
	langid = {english},
	note = {Page Version {ID}: 1062380476},
}

@inreference{noauthor_github_2021,
	title = {{GitHub}},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://de.wikipedia.org/w/index.php?title=GitHub&oldid=218104003},
	abstract = {{GitHub} ist ein netzbasierter Dienst zur Versionsverwaltung f√ºr Software-Entwicklungsprojekte. Namensgebend war das Versionsverwaltungssystem Git. Das Unternehmen {GitHub}, Inc. hat seinen Sitz in San Francisco in den {USA}. Seit dem 26. Dezember 2018 geh√∂rt das Unternehmen zu Microsoft.
√Ñhnliche Dienste sind {GitLab}, Bitbucket und Gitee.},
	booktitle = {Wikipedia},
	urldate = {2022-01-01},
	date = {2021-12-11},
	langid = {german},
	note = {Page Version {ID}: 218104003},
	file = {Snapshot:/home/lars/Zotero/storage/QYFGBNHL/index.html:text/html},
}

@online{noauthor_git_nodate,
	title = {Git Explained: The Basics},
	url = {https://dev.to/milu_franz/git-explained-the-basics-igc},
	shorttitle = {Git Explained},
	abstract = {Git is scary when you are starting up. There is this imminent fear that you could possibly lose hours...},
	titleaddon = {{DEV} Community},
	urldate = {2021-12-30},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/ET7RT2CM/git-explained-the-basics-igc.html:text/html},
}

@online{noauthor_git_nodate-1,
	title = {Git Alternatives \& Competitors},
	url = {https://www.g2.com/products/git/competitors/alternatives},
	abstract = {Find the top-ranking alternatives to Git based on 550 verified user reviews. Read reviews and product information about Azure {DevOps} Server, Helix Core and {AWS} {CodeCommit}.},
	titleaddon = {G2},
	urldate = {2022-01-01},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/QD6CGUQ2/alternatives.html:text/html},
}

@online{noauthor_successful_nodate,
	title = {A successful Git branching model},
	url = {http://nvie.com/posts/a-successful-git-branching-model/},
	abstract = {In this post I present a Git branching strategy for developing and releasing software as I‚Äôve used it in many of my projects, and which has turned out to be very successful.},
	titleaddon = {nvie.com},
	urldate = {2022-01-01},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/FMZ3E6LZ/a-successful-git-branching-model.html:text/html},
}

@online{noauthor_top_2021,
	title = {Top 10 {GitHub} Alternatives That You Can Consider},
	url = {https://www.geeksforgeeks.org/top-10-github-alternatives-that-you-can-consider/},
	abstract = {A Computer Science portal for geeks. It contains well written, well thought and well explained computer science and programming articles, quizzes and practice/competitive programming/company interview Questions.},
	titleaddon = {{GeeksforGeeks}},
	urldate = {2022-01-01},
	date = {2021-10-15},
	langid = {english},
	note = {Section: {GBlog}},
	file = {Snapshot:/home/lars/Zotero/storage/ZYRTS422/top-10-github-alternatives-that-you-can-consider.html:text/html},
}

@video{fireship_git_2020,
	title = {Git Explained in 100 Seconds},
	url = {https://www.youtube.com/watch?v=hwP7WQkmECE},
	abstract = {Learn the basics of Git in 100 seconds.

0:09 Initialize a git repo 
0:33 Stage files
0:39 Commit a snapshot
1:12 Branch off into an alternate universe
1:30 Merge a branch into master

Follow me on Github https://github.com/codediodeio
Git Docs: https://git-scm.com/

\#git \#100SecondsOfCode

Install the quiz app ü§ì

{iOS} https://itunes.apple.com/us/app/fires...
Android https://play.google.com/store/apps/de...

Upgrade to Fireship {PRO} at https://fireship.io/pro
Use code {lORhwXd}2 for 25\% off your first payment. 

My {VS} Code Theme

- Atom One Dark 
- vscode-icons
- Fira Code Font},
	author = {{Fireship}},
	urldate = {2022-01-01},
	date = {2020-02-03},
}