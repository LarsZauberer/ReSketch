
@article{liu_effects_nodate,
	title = {The Effects of Memory Replay in Reinforcement Learning},
	abstract = {Experience replay is a key technique behind many recent advances in deep reinforcement learning. Allowing the agent to learn from earlier memories can speed up learning and break undesirable temporal correlations. Despite its widespread application, very little is understood about the properties of experience replay. How does the amount of memory kept affect learning dynamics? Does it help to prioritize certain experiences? In this paper, we address these questions by formulating a dynamical systems {ODE} model of Q-learning with experience replay. We derive analytic solutions of the {ODE} for a simple setting. We show that even in this very simple setting, the amount of memory kept can substantially affect the agent‚Äôs performance‚Äîtoo much or too little memory both slow down learning. Moreover, we characterize regimes where prioritized replay harms the agent‚Äôs learning. We show that our analytic solutions have excellent agreement with experiments. Finally, we propose a simple algorithm for adaptively changing the memory buffer size which achieves consistently good empirical performance.},
	pages = {8},
	author = {Liu, Ruishan and Zou, James},
	langid = {english},
	file = {Liu and Zou - The Effects of Memory Replay in Reinforcement Lear.pdf:/home/lars/Zotero/storage/J6F2TEDB/Liu and Zou - The Effects of Memory Replay in Reinforcement Lear.pdf:application/pdf},
}

@online{james_answer_2019,
	title = {Answer to "How to "Merge" Sequential models in Keras 2.0?"},
	url = {https://stackoverflow.com/a/58152657},
	shorttitle = {Answer to "How to "Merge" Sequential models in Keras 2.0?},
	titleaddon = {Stack Overflow},
	author = {James},
	urldate = {2022-04-20},
	date = {2019-09-29},
	file = {Snapshot:/home/lars/Zotero/storage/TZN9CDY2/how-to-merge-sequential-models-in-keras-2-0.html:text/html},
}

@online{brownlee_loss_2019,
	title = {Loss and Loss Functions for Training Deep Learning Neural Networks},
	url = {https://machinelearningmastery.com/loss-and-loss-functions-for-training-deep-learning-neural-networks/},
	abstract = {Neural networks are trained using stochastic gradient descent and require that you choose a loss function when designing and configuring [‚Ä¶]},
	titleaddon = {Machine Learning Mastery},
	author = {Brownlee, Jason},
	urldate = {2022-04-17},
	date = {2019-01-27},
	langid = {american},
	file = {Snapshot:/home/lars/Zotero/storage/PCUXTMR2/loss-and-loss-functions-for-training-deep-learning-neural-networks.html:text/html},
}

@software{noauthor_tf-agents_2022,
	title = {{TF}-Agents: A reliable, scalable and easy to use {TensorFlow} library for Contextual Bandits and Reinforcement Learning.},
	rights = {Apache-2.0},
	url = {https://github.com/tensorflow/agents/blob/80c5f67f483ad24308c3a348b1c5a82780459c6b/docs/tutorials/1_dqn_tutorial.ipynb},
	shorttitle = {{TF}-Agents},
	abstract = {{TF}-Agents: A reliable, scalable and easy to use {TensorFlow} library for Contextual Bandits and Reinforcement Learning.},
	publisher = {tensorflow},
	urldate = {2022-04-15},
	date = {2022-04-15},
	note = {original-date: 2018-11-17T00:29:12Z},
}

@online{noauthor_environments_nodate,
	title = {Environments {\textbar} {TensorFlow} Agents},
	url = {https://www.tensorflow.org/agents/tutorials/2_environments_tutorial},
	titleaddon = {{TensorFlow}},
	urldate = {2022-04-15},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/7GKRGCRG/2_environments_tutorial.html:text/html},
}

@online{wang_deep_2021,
	title = {Deep Q-Learning Tutorial: {minDQN}},
	url = {https://towardsdatascience.com/deep-q-learning-tutorial-mindqn-2a4c855abffc},
	shorttitle = {Deep Q-Learning Tutorial},
	abstract = {A Practical Guide to Deep Q-Networks},
	titleaddon = {Medium},
	author = {Wang, Mike},
	urldate = {2022-04-15},
	date = {2021-10-03},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/PXU23T4R/deep-q-learning-tutorial-mindqn-2a4c855abffc.html:text/html},
}

@online{jagtap_understanding_2021,
	title = {Understanding Markov Decision Process ({MDP})},
	url = {https://towardsdatascience.com/understanding-the-markov-decision-process-mdp-8f838510f150},
	abstract = {Towards Training Better Reinforcement Learning Agents},
	titleaddon = {Medium},
	author = {Jagtap, Rohan},
	urldate = {2022-04-15},
	date = {2021-02-10},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/WR2MWAVF/understanding-the-markov-decision-process-mdp-8f838510f150.html:text/html},
}

@online{yoon_deep_2019,
	title = {Deep Deterministic Policy Gradients Explained},
	url = {https://towardsdatascience.com/deep-deterministic-policy-gradients-explained-2d94655a9b7b},
	abstract = {Reinforcement Learning in Continuous Action Spaces},
	titleaddon = {Medium},
	author = {Yoon, Chris},
	urldate = {2022-04-14},
	date = {2019-05-23},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/CSJDRD7P/deep-deterministic-policy-gradients-explained-2d94655a9b7b.html:text/html},
}

@online{unzueta_reinforcement_2022,
	title = {Reinforcement Learning: An Introduction},
	url = {https://towardsdatascience.com/reinforcement-learning-an-introduction-a8783f9ea993},
	shorttitle = {Reinforcement Learning},
	abstract = {An introduction to the fundamentals of Reinforcement Learning, all you need to know to get started},
	titleaddon = {Medium},
	author = {Unzueta, Diego},
	urldate = {2022-04-14},
	date = {2022-01-21},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/QSZQLYDW/reinforcement-learning-an-introduction-a8783f9ea993.html:text/html},
}

@article{graves_generating_2014,
	title = {Generating Sequences With Recurrent Neural Networks},
	url = {http://arxiv.org/abs/1308.0850},
	abstract = {This paper shows how Long Short-term Memory recurrent neural networks can be used to generate complex sequences with long-range structure, simply by predicting one data point at a time. The approach is demonstrated for text (where the data are discrete) and online handwriting (where the data are real-valued). It is then extended to handwriting synthesis by allowing the network to condition its predictions on a text sequence. The resulting system is able to generate highly realistic cursive handwriting in a wide variety of styles.},
	journaltitle = {{arXiv}:1308.0850 [cs]},
	author = {Graves, Alex},
	urldate = {2022-04-13},
	date = {2014-06-05},
	eprinttype = {arxiv},
	eprint = {1308.0850},
	keywords = {Computer Science - Computation and Language, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv Fulltext PDF:/home/lars/Zotero/storage/QW8EKZFV/Graves - 2014 - Generating Sequences With Recurrent Neural Network.pdf:application/pdf;arXiv.org Snapshot:/home/lars/Zotero/storage/3LLCCFVT/1308.html:text/html},
}

@article{graves_generating_2014-1,
	title = {Generating Sequences With Recurrent Neural Networks},
	url = {http://arxiv.org/abs/1308.0850},
	abstract = {This paper shows how Long Short-term Memory recurrent neural networks can be used to generate complex sequences with long-range structure, simply by predicting one data point at a time. The approach is demonstrated for text (where the data are discrete) and online handwriting (where the data are real-valued). It is then extended to handwriting synthesis by allowing the network to condition its predictions on a text sequence. The resulting system is able to generate highly realistic cursive handwriting in a wide variety of styles.},
	journaltitle = {{arXiv}:1308.0850 [cs]},
	author = {Graves, Alex},
	urldate = {2022-04-13},
	date = {2014-06-05},
	eprinttype = {arxiv},
	eprint = {1308.0850},
	keywords = {Computer Science - Computation and Language, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv Fulltext PDF:/home/lars/Zotero/storage/V6TE8XP4/Graves - 2014 - Generating Sequences With Recurrent Neural Network.pdf:application/pdf;arXiv.org Snapshot:/home/lars/Zotero/storage/N22N3MTL/1308.html:text/html},
}

@online{noauthor_keras-rl_nodate,
	title = {Keras-{RL} Documentation},
	url = {https://keras-rl.readthedocs.io/en/latest/search.html?q=dqnagent},
	urldate = {2022-04-13},
	file = {Keras-RL Documentation:/home/lars/Zotero/storage/2MLR78NX/search.html:text/html},
}

@online{prathima_kadari_introduction_2021,
	title = {Introduction to Reinforcement Learning for Beginners},
	url = {https://www.analyticsvidhya.com/blog/2021/02/introduction-to-reinforcement-learning-for-beginners/},
	abstract = {Reinforcement Learning is definitely one of the evident research areas at present. This article is an introduction to reinforcement learning},
	titleaddon = {Analytics Vidhya},
	author = {{Prathima Kadari}},
	urldate = {2022-04-01},
	date = {2021-02-21},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/DN58US5V/introduction-to-reinforcement-learning-for-beginners.html:text/html},
}

@article{sutton_reinforcement_2014,
	title = {Reinforcement Learning: An Introduction},
	pages = {352},
	journaltitle = {{MIT} Press},
	author = {Sutton, Richard S and Barto, Andrew G},
	date = {2014},
	langid = {english},
	file = {Sutton und Barto - Reinforcement Learning An Introduction.pdf:/home/lars/Zotero/storage/X3EUZSVH/Sutton und Barto - Reinforcement Learning An Introduction.pdf:application/pdf},
}

@article{zhou_learning_2018,
	title = {Learning to Doodle with Deep Q Networks and Demonstrated Strokes},
	url = {http://arxiv.org/abs/1810.05977},
	abstract = {Doodling is a useful and common intelligent skill that people can learn and master. In this work, we propose a two-stage learning framework to teach a machine to doodle in a simulated painting environment via Stroke Demonstration and deep Q-learning ({SDQ}). The developed system, Doodle-{SDQ}, generates a sequence of pen actions to reproduce a reference drawing and mimics the behavior of human painters. In the first stage, it learns to draw simple strokes by imitating in supervised fashion from a set of strokeaction pairs collected from artist paintings. In the second stage, it is challenged to draw real and more complex doodles without ground truth actions; thus, it is trained with Qlearning. Our experiments confirm that (1) doodling can be learned without direct stepby- step action supervision and (2) pretraining with stroke demonstration via supervised learning is important to improve performance. We further show that Doodle-{SDQ} is effective at producing plausible drawings in different media types, including sketch and watercolor.},
	journaltitle = {{arXiv}:1810.05977 [cs]},
	author = {Zhou, Tao and Fang, Chen and Wang, Zhaowen and Yang, Jimei and Kim, Byungmoon and Chen, Zhili and Brandt, Jonathan and Terzopoulos, Demetri},
	urldate = {2022-03-31},
	date = {2018-10-14},
	eprinttype = {arxiv},
	eprint = {1810.05977},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/lars/Zotero/storage/QJR9FZBA/Zhou et al. - 2018 - Learning to Sketch with Deep Q Networks and Demons.pdf:application/pdf;arXiv.org Snapshot:/home/lars/Zotero/storage/Q6LZ876Z/1810.html:text/html},
}

@inproceedings{zheng_strokenet_2018,
	title = {{StrokeNet}: A Neural Painting Environment},
	url = {https://openreview.net/forum?id=HJxwDiActX},
	shorttitle = {{StrokeNet}},
	abstract = {{StrokeNet} is a novel architecture where the agent is trained to draw by strokes on a differentiable simulation of the environment, which could effectively exploit the power of back-propagation.},
	eventtitle = {International Conference on Learning Representations},
	author = {Zheng, Ningyuan and Jiang, Yifan and Huang, Dingjiang},
	urldate = {2022-03-31},
	date = {2018-09-27},
	langid = {english},
	file = {Full Text PDF:/home/lars/Zotero/storage/L3NKQJNQ/Zheng et al. - 2018 - StrokeNet A Neural Painting Environment.pdf:application/pdf;Snapshot:/home/lars/Zotero/storage/SGR3CCPH/forum.html:text/html},
}

@inproceedings{huang_learning_2019,
	location = {Seoul, Korea (South)},
	title = {Learning to Paint With Model-Based Deep Reinforcement Learning},
	isbn = {978-1-72814-803-8},
	url = {https://ieeexplore.ieee.org/document/9010329/},
	doi = {10.1109/ICCV.2019.00880},
	abstract = {We show how to teach machines to paint like human painters, who can use a small number of strokes to create fantastic paintings. By employing a neural renderer in model-based Deep Reinforcement Learning ({DRL}), our agents learn to determine the position and color of each stroke and make long-term plans to decompose texturerich images into strokes. Experiments demonstrate that excellent visual effects can be achieved using hundreds of strokes. The training process does not require the experience of human painters or stroke tracking data. The code is available at https://github.com/hzwer/ {ICCV}2019-{LearningToPaint}.},
	eventtitle = {2019 {IEEE}/{CVF} International Conference on Computer Vision ({ICCV})},
	pages = {8708--8717},
	booktitle = {2019 {IEEE}/{CVF} International Conference on Computer Vision ({ICCV})},
	publisher = {{IEEE}},
	author = {Huang, Zhewei and Zhou, Shuchang and Heng, Wen},
	urldate = {2022-03-31},
	date = {2019-10},
	langid = {english},
	file = {Huang et al. - 2019 - Learning to Paint With Model-Based Deep Reinforcem.pdf:/home/lars/Zotero/storage/XHDX6M3D/Huang et al. - 2019 - Learning to Paint With Model-Based Deep Reinforcem.pdf:application/pdf},
}

@online{cal_esg_-_eecs_cs294-112_nodate,
	title = {{CS}294-112 Deep Reinforcement Learning Sp17 - {YouTube}},
	url = {https://www.youtube.com/playlist?list=PLkFD6_40KJIwTmSbCv9OVJB3YaO4sFwkX},
	author = {{CAL ESG - EECS}},
	urldate = {2022-03-27},
	file = {CS294-112 Deep Reinforcement Learning Sp17 - YouTube:/home/lars/Zotero/storage/D2S2XDWM/playlist.html:text/html},
}

@video{cognizant_ai_2019,
	title = {{AI} and Evolutionary Computation Experts Q\&A {\textbar} Jeff Clune {\textbar} Cognizant},
	url = {https://www.youtube.com/watch?app=desktop&v=0XCsNwvfJos&ab_channel=Cognizant},
	abstract = {Evolution has a key role to play as we push towards Artificial General Intelligence ({AGI}), mainly for three reasons. Firstly the neural evolution and the evolutionary algorithms communities have developed a lot of important ideas that have a role to play in general {AI} research whether or not they ultimately are used on an evolutionary backbone or they're hybridized with other ideas. Secondly evolutionary algorithms themselves may be a key technology for evolution in terms of having a part to play in the overall solution to {AI}. Third, to some extent these names for different fields are metaphorical and so if one thinks about evolution a little bit more broadly as the outer loop learning algorithm which is to say that we have something that kind of moves and learns across generations and then something that learns within a lifetime that outer loop which in nature is evolution and in machine learning sometimes is specifically an evolutionary algorithm or sometimes could be, say reinforcement learning algorithm that outer loop that is definitely going to be critical as we push towards {AGI} and some will call evolution, and some will fail to call it evolution. But at its heart, we're taking inspiration from natural evolution and evolutionary algorithms to do that outer loop activity, and that's essential. So in many different ways, evolutionary algorithms are going to be essential to our push towards {AI}, and we will increasingly see that the machine learning community is starting to take note and play with a lot of the ideas from evolution under its various interpretations and definitions. 

Learn more: https://cognizant.com/ai
Subscribe to this channel: https://cogniz.at/subscribeyt},
	author = {{Cognizant}},
	urldate = {2022-03-27},
	date = {2019-08-29},
}

@inproceedings{lin_dynamic_2019,
	title = {Dynamic Model Pruning with Feedback},
	url = {https://openreview.net/forum?id=SJem8lSFwB},
	abstract = {Deep neural networks often have millions of parameters. This can hinder their deployment to low-end devices, not only due to high memory requirements but also because of increased latency at...},
	eventtitle = {International Conference on Learning Representations},
	author = {Lin, Tao and Stich, Sebastian U. and Barba, Luis and Dmitriev, Daniil and Jaggi, Martin},
	urldate = {2022-03-27},
	date = {2019-09-25},
	langid = {english},
	file = {Full Text PDF:/home/lars/Zotero/storage/TCH3J44A/Lin et al. - 2019 - Dynamic Model Pruning with Feedback.pdf:application/pdf;Snapshot:/home/lars/Zotero/storage/WBVPI3WB/forum.html:text/html},
}

@software{palo_intelligent_2021,
	title = {Intelligent Control Techniques for Robot Manipulators.},
	url = {https://github.com/normandipalo/intelligent-control-techniques-for-robots/blob/af82092b6e5ce187f9c1912656d7dc45a23e119d/report.pdf},
	abstract = {An analysis of different intelligent control techniques (evolutionary alg., reinf. learn., neural networks) applied to robotic manipulators.},
	author = {Palo, Norman Di},
	urldate = {2022-03-27},
	date = {2021-09-25},
	note = {original-date: 2017-08-14T10:44:52Z},
}

@online{palo_making_2017,
	title = {Making a robot learn how to move, part 2 ‚Äì reinforcement learning in the real, wild world},
	url = {https://towardsdatascience.com/making-a-robot-learn-how-to-move-part-2-reinforcement-learning-in-the-real-wild-world-9427da7b9b21},
	abstract = {Tackling the bottlenecks of the physical world.},
	titleaddon = {Medium},
	author = {Palo, Norman Di},
	urldate = {2022-03-27},
	date = {2017-08-22},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/R49L3ETT/making-a-robot-learn-how-to-move-part-2-reinforcement-learning-in-the-real-wild-world-9427da7b9.html:text/html},
}

@online{palo_making_2017-1,
	title = {Making a robot learn how to move, part 1 ‚Äî Evolutionary algorithms},
	url = {https://towardsdatascience.com/making-a-robot-learn-how-to-move-part-1-evolutionary-algorithms-340f239c9cd2},
	abstract = {How nature inspires engineering.},
	titleaddon = {Medium},
	author = {Palo, Norman Di},
	urldate = {2022-03-27},
	date = {2017-08-14},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/MTBSRV6R/making-a-robot-learn-how-to-move-part-1-evolutionary-algorithms-340f239c9cd2.html:text/html},
}

@online{palo_making_2017-2,
	title = {Making a robot learn how to move ‚Äî Intro},
	url = {https://towardsdatascience.com/making-a-robot-learn-of-to-move-intro-2bcf3c3330df},
	abstract = {(or: where Artificial Intelligence meets Robotics)},
	titleaddon = {Medium},
	author = {Palo, Norman Di},
	urldate = {2022-03-27},
	date = {2017-08-14},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/LGYC25T9/making-a-robot-learn-of-to-move-intro-2bcf3c3330df.html:text/html},
}

@online{noauthor_introduction_nodate,
	title = {Introduction to {RL} and Deep Q Networks {\textbar} {TensorFlow} Agents},
	url = {https://www.tensorflow.org/agents/tutorials/0_intro_rl},
	titleaddon = {{TensorFlow}},
	urldate = {2022-03-22},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/TE9EVVW5/0_intro_rl.html:text/html},
}

@software{noauthor_tf-agents_2022-1,
	title = {{TF}-Agents: A reliable, scalable and easy to use {TensorFlow} library for Contextual Bandits and Reinforcement Learning.},
	rights = {Apache-2.0},
	url = {https://github.com/tensorflow/agents/blob/10ad6b054bb508adc5a8543ea4849d21f6cc6304/docs/tutorials/8_networks_tutorial.ipynb},
	shorttitle = {{TF}-Agents},
	abstract = {{TF}-Agents: A reliable, scalable and easy to use {TensorFlow} library for Contextual Bandits and Reinforcement Learning.},
	publisher = {tensorflow},
	urldate = {2022-04-21},
	date = {2022-04-19},
	note = {original-date: 2018-11-17T00:29:12Z},
}

@online{noauthor_networks_nodate,
	title = {Networks {\textbar} {TensorFlow} Agents},
	url = {https://www.tensorflow.org/agents/tutorials/8_networks_tutorial},
	titleaddon = {{TensorFlow}},
	urldate = {2022-04-21},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/J9MQ7WL5/8_networks_tutorial.html:text/html},
}

@online{noauthor_tf_agentsagentsddpgcritic_networkcriticnetwork_nodate,
	title = {tf\_agents.agents.ddpg.critic\_network.{CriticNetwork} {\textbar} {TensorFlow} Agents},
	url = {https://www.tensorflow.org/agents/api_docs/python/tf_agents/agents/ddpg/critic_network/CriticNetwork},
	abstract = {Creates a critic network.},
	titleaddon = {{TensorFlow}},
	urldate = {2022-04-21},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/X4SPADMX/CriticNetwork.html:text/html},
}

@online{noauthor_tf_agentsagentsddpgagent_nodate,
	title = {tf\_agents.agents.{DdpgAgent} {\textbar} {TensorFlow} Agents},
	url = {https://www.tensorflow.org/agents/api_docs/python/tf_agents/agents/DdpgAgent},
	abstract = {A {DDPG} Agent.},
	urldate = {2022-04-21},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/ZG65EZTC/DdpgAgent.html:text/html},
}

@article{nielsen_neural_2015,
	title = {Neural Networks and Deep Learning},
	url = {http://neuralnetworksanddeeplearning.com},
	author = {Nielsen, Michael A.},
	urldate = {2022-04-22},
	date = {2015},
	langid = {english},
	note = {Publisher: Determination Press},
	file = {Snapshot:/home/lars/Zotero/storage/GNB5Y64V/chap1.html:text/html},
}

@online{deshpande_adit_nodate,
	title = {Adit Deshpande ‚Äì Engineering at Forward {\textbar} {UCLA} {CS} '19},
	url = {https://adeshpande3.github.io/},
	abstract = {Engineering at Forward {\textbar} {UCLA} {CS} '19},
	author = {Deshpande, Adit},
	urldate = {2022-04-22},
	file = {Snapshot:/home/lars/Zotero/storage/W7GQGQ78/adeshpande3.github.io.html:text/html},
}

@software{padmaja-kulkarni_tfagents_examples_2021,
	title = {{TFAgents}\_examples},
	url = {https://github.com/padmaja-kulkarni/TFAgents_examples/blob/b06f3cf9aed20e87986eaacff4d1ab664d9de2e7/DDPG_pendulum.ipynb},
	author = {padmaja-kulkarni},
	urldate = {2022-04-22},
	date = {2021-05-04},
	note = {original-date: 2021-02-12T13:33:35Z},
}

@online{noauthor_python_nodate,
	title = {python error :Using Tensorflow Agents to realize reinforcement Learning {DQN}},
	url = {https://www.codestudyblog.com/cs2112pyc/1230143023.html},
	urldate = {2022-04-23},
	file = {python error \:Using Tensorflow Agents to realize reinforcement Learning DQN:/home/lars/Zotero/storage/N7HSBQ2U/1230143023.html:text/html},
}

@online{brownlee_why_2021,
	title = {Why Optimization Is Important in Machine Learning},
	url = {https://machinelearningmastery.com/why-optimization-is-important-in-machine-learning/},
	abstract = {Machine learning involves using an algorithm to learn and generalize from historical data in order to make predictions on new data. This problem can be described as approximating a function that maps examples of inputs to examples of outputs. Approximating a function can be solved by framing the problem as function optimization. This is where [‚Ä¶]},
	titleaddon = {Machine Learning Mastery},
	author = {Brownlee, Jason},
	urldate = {2022-07-20},
	date = {2021-06-01},
	langid = {american},
	file = {Snapshot:/home/lars/Zotero/storage/SG6SHWT9/why-optimization-is-important-in-machine-learning.html:text/html},
}

@online{uwe_schick_was_2018,
	title = {Was ist k√ºnstliche Intelligenz? {\textbar} {KI} Definition},
	url = {https://news.sap.com/germany/2018/03/was-ist-kuenstliche-intelligenz/},
	shorttitle = {Was ist k√ºnstliche Intelligenz?},
	abstract = {Welche Vorteile bringen K√ºnstliche Intelligenz ({KI}) und maschinelles Lernen? Von neuronalen Netzen √ºber Deep-Learning bis zu Gesch√§ftsszenarien. Lesen},
	titleaddon = {{SAP} News Center},
	author = {{Uwe Schick}},
	urldate = {2022-06-29},
	date = {2018-03-20},
	langid = {german},
	file = {Snapshot:/home/lars/Zotero/storage/2L6UQ2NC/was-ist-kuenstliche-intelligenz.html:text/html},
}

@online{laurenz_wuttke_was_2021,
	title = {Was ist Unsupervised Learning (Un√ºberwachtes Lernen)?},
	url = {https://datasolut.com/wiki/unsupervised-learning/},
	abstract = {Unsupervised Learning im √úberblick: Lernen Sie, was un√ºberwachtes Lernen ist und welche Methoden und Beispiele es gibt.},
	titleaddon = {datasolut {GmbH}},
	author = {{Laurenz Wuttke}},
	urldate = {2022-06-25},
	date = {2021-10-04},
	langid = {german},
	file = {Snapshot:/home/lars/Zotero/storage/IWY3W85S/unsupervised-learning.html:text/html},
}

@online{arora_supervised_2020,
	title = {Supervised vs Unsupervised vs Reinforcement},
	url = {https://www.aitude.com/supervised-vs-unsupervised-vs-reinforcement/},
	abstract = {The amount of data generated in the world today is very huge. This data is generated not only by humans but also by smartphones, computers and other devices. Based on the kind of data available and a motive present, certainly, a programmer will choose how to train an algorithm using a specific learning model. Machine [‚Ä¶]},
	titleaddon = {{AITUDE}},
	author = {Arora, Surbhi},
	urldate = {2022-06-25},
	date = {2020-01-29},
	langid = {american},
	file = {Snapshot:/home/lars/Zotero/storage/NF67J7WH/supervised-vs-unsupervised-vs-reinforcement.html:text/html},
}

@online{noauthor_what_nodate,
	title = {What is Artificial Intelligence ({AI})? {\textbar} Glossary},
	url = {https://www.hpe.com/ch/de/what-is/artificial-intelligence.html},
	shorttitle = {What is Artificial Intelligence ({AI})?},
	abstract = {Artificial intelligence ({AI}) broadly refers to any human-like behavior displayed by a machine or system. In {AI}‚Äôs most basic form, computers are programmed to ‚Äúmimic‚Äù human behavior using extensive data from past examples of similar behavior. {\textbar} {HPE} Schweiz},
	urldate = {2022-06-21},
	langid = {german},
	file = {Snapshot:/home/lars/Zotero/storage/ZUMGS7LE/artificial-intelligence.html:text/html},
}

@online{noauthor_what_nodate-1,
	title = {What is Machine Learning? {\textbar} Glossary},
	url = {https://www.hpe.com/ch/de/what-is/machine-learning.html},
	shorttitle = {What is Machine Learning?},
	abstract = {Machine learning occurs when software is able to successfully predict and react to unfolding scenarios based on previous outcomes without human input. {\textbar} {HPE} Schweiz},
	urldate = {2022-06-21},
	langid = {german},
	file = {Snapshot:/home/lars/Zotero/storage/TEIDKBFJ/machine-learning.html:text/html},
}

@online{noauthor_duden_nodate,
	title = {Duden {\textbar} Roboter {\textbar} Rechtschreibung, Bedeutung, Definition, Herkunft},
	url = {https://www.duden.de/rechtschreibung/Roboter},
	abstract = {Definition, Rechtschreibung, Synonyme und Grammatik von 'Roboter' auf Duden online nachschlagen. W√∂rterbuch der deutschen Sprache.},
	urldate = {2022-06-19},
	langid = {german},
	file = {Snapshot:/home/lars/Zotero/storage/H72HBNPD/Roboter.html:text/html},
}

@online{ai_brief_2019,
	title = {A brief overview of Imitation Learning},
	url = {https://smartlabai.medium.com/a-brief-overview-of-imitation-learning-8a8a75c44a9c},
	abstract = {Author: Zolt√°n L≈ërincz},
	titleaddon = {Medium},
	author = {{AI}, {SmartLab}},
	urldate = {2022-06-19},
	date = {2019-09-19},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/QH6ML9HQ/a-brief-overview-of-imitation-learning-8a8a75c44a9c.html:text/html},
}

@online{noauthor_physics_nodate,
	title = {physics of drawing},
	url = {https://prezi.com/ggratirdoenz/physics-of-drawing/},
	abstract = {2nd law : force = mass x acceleration 3rd law:For every action there is an equal and opposite reaction. this is applied when shading a picture or coloring it black-white. this is because of the amount of force you apply to the pencil depends on the darkness/lightness. When you're},
	titleaddon = {prezi.com},
	urldate = {2022-06-19},
	langid = {german},
	file = {Snapshot:/home/lars/Zotero/storage/JVA6B33A/physics-of-drawing.html:text/html},
}

@online{jan-dirk_kranz_deep_2019,
	title = {Deep Learning vs Machine Learning - Was ist der Unterschied?},
	url = {https://it-talents.de/it-wissen/programmieren/deep-learning-vs-machine-learning-was-ist-der-unterschied/},
	abstract = {Die Fortschritte im Bereich der k√ºnstlichen Intelligenz sind f√ºr viele Zeitgenossen eher unverst√§ndlich. Doch im Grunde l√§uft es auf zwei Konzepte hinaus, von denen Du‚Ä¶},
	titleaddon = {{IT}-Talents.de},
	author = {{Jan-Dirk Kranz}},
	urldate = {2022-06-18},
	date = {2019-04-03},
	langid = {german},
	file = {Snapshot:/home/lars/Zotero/storage/VG2VMKVG/deep-learning-vs-machine-learning-was-ist-der-unterschied.html:text/html},
}

@article{nielsen_neural_2015-1,
	title = {Neural Networks and Deep Learning},
	url = {http://neuralnetworksanddeeplearning.com},
	author = {Nielsen, Michael A.},
	urldate = {2022-05-04},
	date = {2015},
	langid = {english},
	note = {Publisher: Determination Press},
	file = {Snapshot:/home/lars/Zotero/storage/L3IJI8YR/chap1.html:text/html},
}

@online{deshpande_beginners_nodate,
	title = {A Beginner's Guide To Understanding Convolutional Neural Networks Part 2},
	url = {https://adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks-Part-2/},
	abstract = {{ReLUs}, Pooling, Dropout...(aka The Fun Stuff)},
	author = {Deshpande, Adit},
	urldate = {2022-04-28},
	file = {Snapshot:/home/lars/Zotero/storage/M2VEVA57/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks-Part-2.html:text/html},
}

@online{ankit_choudhary_deep_2019,
	title = {Deep Q-Learning {\textbar} An Introduction To Deep Reinforcement Learning},
	url = {https://www.analyticsvidhya.com/blog/2019/04/introduction-deep-q-learning-python/},
	abstract = {An Introduction To Deep Reinforcement Learning. Learn about deep Q-learning, and build a deep Q-learning model in Python using keras and gym.},
	titleaddon = {Analytics Vidhya},
	author = {{Ankit Choudhary}},
	urldate = {2022-04-25},
	date = {2019-04-18},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/X9KIV4CV/introduction-deep-q-learning-python.html:text/html},
}

@online{ad_how_2018,
	title = {How exactly to compute Deep Q-Learning Loss Function?},
	url = {https://stats.stackexchange.com/q/249355},
	titleaddon = {Cross Validated},
	author = {A.D},
	urldate = {2022-04-25},
	date = {2018-07-06},
}

@online{ad_answer_2016,
	title = {Answer to "How exactly to compute Deep Q-Learning Loss Function?"},
	url = {https://stats.stackexchange.com/a/250005},
	shorttitle = {Answer to "How exactly to compute Deep Q-Learning Loss Function?},
	titleaddon = {Cross Validated},
	author = {A.D},
	urldate = {2022-04-25},
	date = {2016-12-06},
	file = {Snapshot:/home/lars/Zotero/storage/Y3JNFQX9/how-exactly-to-compute-deep-q-learning-loss-function.html:text/html},
}

@online{ad_how_2018-1,
	title = {How exactly to compute Deep Q-Learning Loss Function?},
	url = {https://stats.stackexchange.com/q/249355},
	titleaddon = {Cross Validated},
	author = {A.D},
	urldate = {2022-04-25},
	date = {2018-07-06},
	file = {Snapshot:/home/lars/Zotero/storage/LVRJYBI2/how-exactly-to-compute-deep-q-learning-loss-function.html:text/html},
}

@inreference{noauthor_git_2021,
	title = {Git},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=Git&oldid=1062380476},
	abstract = {Git () is software for tracking changes in any set of files, usually used for coordinating work among programmers collaboratively developing source code during software development. Its goals include speed, data integrity, and support for distributed, non-linear workflows (thousands of parallel branches running on different systems).Git was created by Linus Torvalds in 2005 for development of the Linux kernel, with other kernel developers contributing to its initial development. Since 2005, Junio Hamano has been the core maintainer. As with most other distributed version control systems, and unlike most client‚Äìserver systems, every Git directory on every computer is a full-fledged repository with complete history and full version-tracking abilities, independent of network access or a central server. Git is free and open-source software distributed under the {GPL}-2.0-only license.},
	booktitle = {Wikipedia},
	urldate = {2021-12-30},
	date = {2021-12-28},
	langid = {english},
	note = {Page Version {ID}: 1062380476},
}

@inreference{noauthor_github_2021,
	title = {{GitHub}},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://de.wikipedia.org/w/index.php?title=GitHub&oldid=218104003},
	abstract = {{GitHub} ist ein netzbasierter Dienst zur Versionsverwaltung f√ºr Software-Entwicklungsprojekte. Namensgebend war das Versionsverwaltungssystem Git. Das Unternehmen {GitHub}, Inc. hat seinen Sitz in San Francisco in den {USA}. Seit dem 26. Dezember 2018 geh√∂rt das Unternehmen zu Microsoft.
√Ñhnliche Dienste sind {GitLab}, Bitbucket und Gitee.},
	booktitle = {Wikipedia},
	urldate = {2022-01-01},
	date = {2021-12-11},
	langid = {german},
	note = {Page Version {ID}: 218104003},
	file = {Snapshot:/home/lars/Zotero/storage/QYFGBNHL/index.html:text/html},
}

@online{milu_git_2020,
	title = {Git Explained: The Basics},
	url = {https://dev.to/milu_franz/git-explained-the-basics-igc},
	shorttitle = {Git Explained},
	abstract = {Git is scary when you are starting up. There is this imminent fear that you could possibly lose hours...},
	titleaddon = {{DEV} Community},
	author = {{Milu}},
	urldate = {2021-12-30},
	date = {2020-05-09},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/ET7RT2CM/git-explained-the-basics-igc.html:text/html},
}

@online{noauthor_git_nodate,
	title = {Git Alternatives \& Competitors},
	url = {https://www.g2.com/products/git/competitors/alternatives},
	abstract = {Find the top-ranking alternatives to Git based on 550 verified user reviews. Read reviews and product information about Azure {DevOps} Server, Helix Core and {AWS} {CodeCommit}.},
	titleaddon = {G2},
	urldate = {2022-01-01},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/QD6CGUQ2/alternatives.html:text/html},
}

@online{vincent_driessen_successful_2010,
	title = {A successful Git branching model},
	url = {http://nvie.com/posts/a-successful-git-branching-model/},
	abstract = {In this post I present a Git branching strategy for developing and releasing software as I‚Äôve used it in many of my projects, and which has turned out to be very successful.},
	titleaddon = {nvie.com},
	author = {{Vincent Driessen}},
	urldate = {2022-01-01},
	date = {2010-05-01},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/FMZ3E6LZ/a-successful-git-branching-model.html:text/html},
}

@online{ashugupta917gfg_top_2021,
	title = {Top 10 {GitHub} Alternatives That You Can Consider},
	url = {https://www.geeksforgeeks.org/top-10-github-alternatives-that-you-can-consider/},
	abstract = {A Computer Science portal for geeks. It contains well written, well thought and well explained computer science and programming articles, quizzes and practice/competitive programming/company interview Questions.},
	titleaddon = {{GeeksforGeeks}},
	author = {{ashugupta917gfg}},
	urldate = {2022-01-01},
	date = {2021-10-15},
	langid = {english},
	note = {Section: {GBlog}},
	file = {Snapshot:/home/lars/Zotero/storage/ZYRTS422/top-10-github-alternatives-that-you-can-consider.html:text/html},
}

@video{fireship_git_2020,
	title = {Git Explained in 100 Seconds},
	url = {https://www.youtube.com/watch?v=hwP7WQkmECE},
	abstract = {Learn the basics of Git in 100 seconds.

0:09 Initialize a git repo 
0:33 Stage files
0:39 Commit a snapshot
1:12 Branch off into an alternate universe
1:30 Merge a branch into master

Follow me on Github https://github.com/codediodeio
Git Docs: https://git-scm.com/

\#git \#100SecondsOfCode

Install the quiz app ü§ì

{iOS} https://itunes.apple.com/us/app/fires...
Android https://play.google.com/store/apps/de...

Upgrade to Fireship {PRO} at https://fireship.io/pro
Use code {lORhwXd}2 for 25\% off your first payment. 

My {VS} Code Theme

- Atom One Dark 
- vscode-icons
- Fira Code Font},
	author = {{Fireship}},
	urldate = {2022-01-01},
	date = {2020-02-03},
}

@online{noauthor_hyperparameter-abstimmung_nodate,
	title = {Hyperparameter-Abstimmung {\textbar} {AI} Platform Training},
	url = {https://cloud.google.com/ai-platform/training/docs/hyperparameter-tuning-overview?hl=de},
	titleaddon = {Google Cloud},
	urldate = {2022-07-25},
	langid = {german},
}

@software{fernando_nogueira_bayesian_2014,
	title = {Bayesian Optimization: Open source constrained global optimization tool for Python},
	rights = {{MIT}},
	url = {https://github.com/fmfn/BayesianOptimization},
	abstract = {A Python implementation of global optimization with gaussian processes.},
	author = {{Fernando Nogueira}},
	urldate = {2022-07-25},
	date = {2014},
	note = {original-date: 2014-06-06T08:18:56Z},
	keywords = {bayesian-optimization, gaussian-processes, optimization, python, simple},
}

@inreference{noauthor_hyperparameter_2022,
	title = {Hyperparameter optimization},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=Hyperparameter_optimization&oldid=1097116690},
	abstract = {In machine learning, hyperparameter optimization or tuning is the problem of choosing a set of optimal hyperparameters for a learning algorithm. A hyperparameter is a parameter whose value is used to control the learning process. By contrast, the values of other parameters (typically node weights) are learned.
The same kind of machine learning model can require different constraints, weights or learning rates to generalize different data patterns. These measures are called hyperparameters, and have to be tuned so that the model can optimally solve the machine learning problem. Hyperparameter optimization finds a tuple of hyperparameters that yields an optimal model which minimizes a predefined loss function on given independent data.  The objective function takes a tuple of hyperparameters and returns the associated loss. Cross-validation is often used to estimate this generalization performance.},
	booktitle = {Wikipedia},
	urldate = {2022-07-25},
	date = {2022-07-08},
	langid = {english},
	note = {Page Version {ID}: 1097116690},
	file = {Snapshot:/home/lars/Zotero/storage/ZHP3Z9IU/Hyperparameter_optimization.html:text/html},
}

@online{guo_ai_nodate,
	title = {{AI} Notes: Parameter optimization in neural networks},
	url = {https://www.deeplearning.ai/ai-notes/optimization/},
	shorttitle = {{AI} Notes},
	abstract = {Training a machine learning model is a matter of closing the gap between the model's predictions and the observed training data labels. But optimizing the model parameters isn't so straightforward...},
	titleaddon = {deeplearning.ai},
	author = {Guo, Jingru},
	urldate = {2022-07-25},
	file = {Snapshot:/home/lars/Zotero/storage/DW6FSLKA/optimization.html:text/html},
}

@online{christopher_dole_i_nodate,
	title = {A.I. Optimization Demystified ‚Äì Soothsayer Analytics},
	url = {https://soothsayeranalytics.com/de/a-i-optimization-demystified/},
	author = {{Christopher Dole}},
	urldate = {2022-07-25},
	langid = {german},
	file = {Snapshot:/home/lars/Zotero/storage/XYEFJR46/a-i-optimization-demystified.html:text/html},
}

@online{ruben_fiszel_reinforcement_2016,
	title = {Reinforcement Learning and {DQN}, learning to play from pixels - Ruben Fiszel's website},
	url = {https://rubenfiszel.github.io/posts/rl4j/2016-08-24-Reinforcement-Learning-and-DQN.html},
	author = {{Ruben Fiszel}},
	urldate = {2022-07-21},
	date = {2016-08-24},
	file = {Reinforcement Learning and DQN, learning to play from pixels - Ruben Fiszel's website:/home/lars/Zotero/storage/JWXUGC28/2016-08-24-Reinforcement-Learning-and-DQN.html:text/html},
}

@online{noauthor_duden_nodate-1,
	title = {Duden {\textbar} Roboter {\textbar} Rechtschreibung, Bedeutung, Definition, Herkunft},
	url = {https://www.duden.de/rechtschreibung/Roboter},
	abstract = {Definition, Rechtschreibung, Synonyme und Grammatik von 'Roboter' auf Duden online nachschlagen. W√∂rterbuch der deutschen Sprache.},
	urldate = {2022-07-30},
	langid = {german},
	file = {Snapshot:/home/lars/Zotero/storage/K8N9K45D/Roboter.html:text/html},
}

@software{mazzia__2022,
	title = {{\textasciitilde} Efficient-{CapsNet} {\textasciitilde}},
	rights = {Apache-2.0},
	url = {https://github.com/EscVM/Efficient-CapsNet},
	abstract = {Official {TensorFlow} code for the paper "Efficient-{CapsNet}: Capsule Network with Self-Attention Routing".},
	author = {{Mazzia} and {Vittorio} and {Salvetti} and {Francesco} and {Chiaberge} and {Marcello}},
	urldate = {2022-08-03},
	date = {2022-07-29},
	note = {original-date: 2020-12-29T18:13:43Z},
	keywords = {capsule-network, computer-vision, deep-learning, tensorflow},
}

@article{mazzia_vittorio_und_salvetti_francesco_und_chiaberge_marcello_efficient-capsnet_2021,
	title = {Efficient-{CapsNet}: capsule network with self-attention routing},
	volume = {11},
	rights = {Nature Publishing Group},
	url = {https://github.com/EscVM/Efficient-CapsNet},
	journaltitle = {Scientific reports},
	author = {{Mazzia, Vittorio und Salvetti, Francesco und Chiaberge, Marcello}},
	urldate = {2022-08-03},
	date = {2021},
}

@software{lam_linus_keras_2022,
	title = {Keras {DenseNet} 121 for Quick, Draw! Doodle Recognition Challenge},
	rights = {{MIT}},
	url = {https://github.com/lamhoangtung/densenet121-quickdraw-doodle-recognition-challenge},
	abstract = {My solution for Quick, Draw! Doodle Recognition Challenge from Google using Keras {DenseNet} 121},
	author = {L√¢m (Linus), Ho√†ng T√πng},
	urldate = {2022-08-28},
	date = {2022-08-12},
	note = {original-date: 2018-12-09T03:16:32Z},
	keywords = {deep-learning, densenet-keras, doodle-recognizer, kaggle-competition},
}

@software{noauthor_quick_2022,
	title = {Quick, Draw! Image Recognition},
	url = {https://github.com/Lexie88rus/quick-draw-image-recognition},
	abstract = {Recognition of Quick Draw doodles},
	urldate = {2022-08-28},
	date = {2022-08-28},
	note = {original-date: 2019-04-30T10:10:02Z},
}

@online{singh_converting_2021,
	title = {Converting A Model From Pytorch To Tensorflow: Guide To {ONNX}},
	url = {https://analyticsindiamag.com/converting-a-model-from-pytorch-to-tensorflow-guide-to-onnx/},
	shorttitle = {Converting A Model From Pytorch To Tensorflow},
	abstract = {{ONNX} overcomes the problem of framework lock-in by providing an universal intermediary format built to represent machine learning models},
	titleaddon = {Analytics India Magazine},
	author = {Singh, Aditya},
	urldate = {2022-08-29},
	date = {2021-03-08},
	langid = {american},
	file = {Snapshot:/home/lars/Zotero/storage/CULA2VY7/converting-a-model-from-pytorch-to-tensorflow-guide-to-onnx.html:text/html},
}

@video{paretos_bayesian_2021,
	title = {Bayesian Optimization (Bayes Opt): Easy explanation of popular hyperparameter tuning method},
	url = {https://www.youtube.com/watch?v=M-NTkxfd7-8},
	shorttitle = {Bayesian Optimization (Bayes Opt)},
	author = {{paretos}},
	urldate = {2022-09-22},
	date = {2021-01-25},
}

@online{phd_how_2021,
	title = {How To Model Experience Replay, Batch Learning and Target Networks},
	url = {https://towardsdatascience.com/how-to-model-experience-replay-batch-learning-and-target-networks-c1350db93172},
	abstract = {A quick tutorial on three essential tricks for stable and successful Deep Q-learning, using {TensorFlow} 2.0},
	titleaddon = {Medium},
	author = {van Heeswijk, Wouter},
	urldate = {2022-09-16},
	date = {2021-08-30},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/H2LF52Q2/how-to-model-experience-replay-batch-learning-and-target-networks-c1350db93172.html:text/html},
}

@article{jang_q-learning_2019,
	title = {Q-Learning Algorithms: A Comprehensive Classification and Applications},
	volume = {7},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2019.2941229},
	shorttitle = {Q-Learning Algorithms},
	abstract = {Q-learning is arguably one of the most applied representative reinforcement learning approaches and one of the off-policy strategies. Since the emergence of Q-learning, many studies have described its uses in reinforcement learning and artificial intelligence problems. However, there is an information gap as to how these powerful algorithms can be leveraged and incorporated into general artificial intelligence workflow. Early Q-learning algorithms were unsatisfactory in several aspects and covered a narrow range of applications. It has also been observed that sometimes, this rather powerful algorithm learns unrealistically and overestimates the action values hence abating the overall performance. Recently with the general advances of machine learning, more variants of Q-learning like Deep Q-learning which combines basic Q learning with deep neural networks have been discovered and applied extensively. In this paper, we thoroughly explain how Q-learning evolved by unraveling the mathematical complexities behind it as well its flow from reinforcement learning family of algorithms. Improved variants are fully described, and we categorize Q-learning algorithms into single-agent and multi-agent approaches. Finally, we thoroughly investigate up-to-date research trends and key applications that leverage Q-learning algorithms.},
	pages = {133653--133667},
	journaltitle = {{IEEE} Access},
	author = {Jang, Beakcheol and Kim, Myeonghwi and Harerimana, Gaspard and Kim, Jong Wook},
	date = {2019},
	note = {Conference Name: {IEEE} Access},
	keywords = {Classification algorithms, Machine learning algorithms, Market research, Mathematical model, multi-agent, Q-learning, Reinforcement learning, single-agent},
	file = {IEEE Xplore Abstract Record:/home/lars/Zotero/storage/GWECEXLE/8836506.html:text/html;IEEE Xplore Full Text PDF:/home/lars/Zotero/storage/UVG8WDEF/Jang et al. - 2019 - Q-Learning Algorithms A Comprehensive Classificat.pdf:application/pdf},
}

@article{mnih_playing_nodate,
	title = {Playing Atari with Deep Reinforcement Learning},
	abstract = {We present the Ô¨Årst deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We Ô¨Ånd that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.},
	pages = {9},
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
	langid = {english},
	file = {Mnih et al. - Playing Atari with Deep Reinforcement Learning.pdf:/home/lars/Zotero/storage/9MN2EJHZ/Mnih et al. - Playing Atari with Deep Reinforcement Learning.pdf:application/pdf},
}

@online{piyush_verma_what_2021,
	title = {What is Reinforcement Learning? ‚Äì Overview of How it Works {\textbar} Synopsys},
	url = {https://www.synopsys.com/ai/what-is-reinforcement-learning.html},
	author = {{Piyush Verma} and {Stelios Diamantidis}},
	urldate = {2022-09-16},
	date = {2021-04-27},
	file = {What is Reinforcement Learning? ‚Äì Overview of How it Works | Synopsys:/home/lars/Zotero/storage/SXFPKSTK/what-is-reinforcement-learning.html:text/html},
}

@online{osinski_what_2018,
	title = {What is reinforcement learning? The complete guide},
	url = {https://deepsense.ai/what-is-reinforcement-learning-the-complete-guide/},
	shorttitle = {What is reinforcement learning?},
	abstract = {Although machine learning is seen as a monolith, this cutting-edge technology is diversified, with various sub-types including machine learning, deep learning, and the state-of-the-art technology of deep reinforcement learning.},
	titleaddon = {deepsense.ai},
	author = {Osi≈Ñski, B≈Ça≈ºej and Budek, Konrad},
	urldate = {2022-09-16},
	date = {2018-07-05},
	langid = {american},
	note = {Section: Deep learning},
	file = {Snapshot:/home/lars/Zotero/storage/FUV6ZB2A/what-is-reinforcement-learning-the-complete-guide.html:text/html},
}

@online{team_keras_nodate,
	title = {Keras documentation: Concatenate layer},
	url = {https://keras.io/api/layers/merging_layers/concatenate/},
	shorttitle = {Keras documentation},
	abstract = {Keras documentation},
	author = {Team, Keras},
	urldate = {2022-09-16},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/ZBI5KCKR/concatenate.html:text/html},
}

@online{jayawardana_concatenating_2021,
	title = {Concatenating Multiple Activation Functions and Multiple Poling Layers for Deep Neural Networks},
	url = {https://towardsdatascience.com/concatenating-multiple-activation-functions-and-multiple-poling-layers-for-deep-neural-networks-d48a4b273d30},
	abstract = {By concatenating multiple activation functions and multiple pooling layers, we minimise the probability of weights-decay in‚Ä¶},
	titleaddon = {Medium},
	author = {Jayawardana, Kavinda},
	urldate = {2022-09-16},
	date = {2021-01-03},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/AF4ATJFR/concatenating-multiple-activation-functions-and-multiple-poling-layers-for-deep-neural-networks.html:text/html},
}

@online{unzueta_convolutional_2022,
	title = {Convolutional Layers vs Fully Connected Layers},
	url = {https://towardsdatascience.com/convolutional-layers-vs-fully-connected-layers-364f05ab460b},
	abstract = {What is really going on when you use a convolutional layer vs a fully connected layer?},
	titleaddon = {Medium},
	author = {Unzueta, Diego},
	urldate = {2022-09-16},
	date = {2022-03-15},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/PAZJPWRZ/convolutional-layers-vs-fully-connected-layers-364f05ab460b.html:text/html},
}

@online{malik_what_2019,
	title = {What Are Hidden Layers?},
	url = {https://medium.com/fintechexplained/what-are-hidden-layers-4f54f7328263},
	abstract = {Important Topic To Understand When Working On Machine Learning Models},
	titleaddon = {{FinTechExplained}},
	author = {Malik, Farhad},
	urldate = {2022-09-16},
	date = {2019-05-20},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/TZ4ZEZA4/what-are-hidden-layers-4f54f7328263.html:text/html},
}

@online{ognjanovski_everything_2020,
	title = {Everything you need to know about Neural Networks and Backpropagation ‚Äî Machine Learning Made Easy‚Ä¶},
	url = {https://towardsdatascience.com/everything-you-need-to-know-about-neural-networks-and-backpropagation-machine-learning-made-easy-e5285bc2be3a},
	abstract = {Neural Network explanation from the ground including understanding the math behind it},
	titleaddon = {Medium},
	author = {Ognjanovski, Gavril},
	urldate = {2022-09-16},
	date = {2020-06-07},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/HURCBRM6/everything-you-need-to-know-about-neural-networks-and-backpropagation-machine-learning-made-eas.html:text/html},
}

@online{kumar_sigmoid_2019,
	title = {Sigmoid Neuron ‚Äî Deep Neural Networks},
	url = {https://towardsdatascience.com/sigmoid-neuron-deep-neural-networks-a4cd35b629d7},
	abstract = {The building block of the deep neural networks is called the sigmoid neuron.},
	titleaddon = {Medium},
	author = {Kumar, Niranjan},
	urldate = {2022-09-16},
	date = {2019-12-18},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/URPD6UFK/sigmoid-neuron-deep-neural-networks-a4cd35b629d7.html:text/html},
}

@online{pragati_baheti_activation_2022,
	title = {Activation Functions in Neural Networks [12 Types \& Use Cases]},
	url = {https://www.v7labs.com/blog/neural-networks-activation-functions, https://www.v7labs.com/blog/neural-networks-activation-functions},
	abstract = {A neural network activation function is a function that is applied to the output of a neuron. Learn about different types of activation functions and how they work.},
	author = {{Pragati Baheti}},
	urldate = {2022-09-16},
	date = {2022-07-19},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/ILWPS3US/neural-networks-activation-functions.html:text/html},
}

@online{simplilearn_what_2021,
	title = {What is Perceptron: A Beginners Guide for Perceptron [Updated]},
	url = {https://www.simplilearn.com/tutorials/deep-learning-tutorial/perceptron},
	shorttitle = {What is Perceptron},
	abstract = {A perceptron is a neural network unit and algorithm for supervised learning of binary classifiers. Learn perceptron learning rule, functions, and much more!},
	titleaddon = {Simplilearn.com},
	author = {{Simplilearn}},
	urldate = {2022-09-16},
	date = {2021-05-26},
	langid = {american},
	file = {Snapshot:/home/lars/Zotero/storage/AIEL8HHC/perceptron.html:text/html},
}

@online{noauthor_artificial_nodate,
	title = {Artificial Neural Network Tutorial - Javatpoint},
	url = {https://www.javatpoint.com/artificial-neural-network},
	abstract = {Artificial Neural Network Tutorial with Introduction, History of Artificial Neural Network, What is {ANN}, Adaptive Resonance Theory, Building Blocks, Genetic Algorithm etc.},
	titleaddon = {www.javatpoint.com},
	urldate = {2022-09-16},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/PPDACUKX/artificial-neural-network.html:text/html},
}

@inreference{noauthor_neuronales_2021,
	title = {Neuronales Netz},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://de.wikipedia.org/w/index.php?title=Neuronales_Netz&oldid=210963657},
	abstract = {Als neuronales Netz wird in den Neurowissenschaften eine beliebige Anzahl miteinander verbundener Neuronen bezeichnet, die als Teil eines Nervensystems einen Zusammenhang bilden, der einer bestimmten Funktion dienen soll. Abstrahiert werden in Computational Neuroscience darunter auch vereinfachte Modelle einer biologischen Vernetzung verstanden.
In der Informatik, Informationstechnik und Robotik werden deren Strukturen als k√ºnstliches neuronales Netz modelliert und technisch nachgebildet, simuliert und abgewandelt.},
	booktitle = {Wikipedia},
	urldate = {2022-09-16},
	date = {2021-04-15},
	langid = {german},
	note = {Page Version {ID}: 210963657},
	file = {Snapshot:/home/lars/Zotero/storage/7IW54APK/Neuronales_Netz.html:text/html},
}

@online{nyuytiymbiy_parameters_2022,
	title = {Parameters and Hyperparameters in Machine Learning and Deep Learning},
	url = {https://towardsdatascience.com/parameters-and-hyperparameters-aa609601a9ac},
	abstract = {What exactly are they and how do they interact?},
	titleaddon = {Medium},
	author = {Nyuytiymbiy, Kizito},
	urldate = {2022-09-16},
	date = {2022-03-28},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/2AYVGJKX/parameters-and-hyperparameters-aa609601a9ac.html:text/html},
}

@online{luis_g_serrano_21_2021,
	title = {2.1 What is the difference between labelled and unlabelled data? ¬∑ Grokking Machine Learning},
	url = {https://livebook.manning.com/book/grokking-machine-learning/2-1-what-is-the-difference-between-labelled-and-unlabelled-data-/v-4/},
	shorttitle = {2.1 What is the difference between labelled and unlabelled data?},
	abstract = {Three main different types of machine learning.; The difference between labelled and unlabelled data.; What supervised learning is and what it‚Äôs useful for.; The difference between regression and classification, and what are they useful for.; What unsupervised learning is and what it‚Äôs useful for.; What reinforcement learning is and what it‚Äôs useful for.;},
	author = {{Luis G. Serrano}},
	urldate = {2022-09-16},
	date = {2021-12-14},
	langid = {american},
	file = {Snapshot:/home/lars/Zotero/storage/S3ZKLYR6/v-4.html:text/html},
}

@online{noauthor_training_nodate,
	title = {Training and Test Sets: Splitting Data {\textbar} Machine Learning},
	url = {https://developers.google.com/machine-learning/crash-course/training-and-test-sets/splitting-data},
	shorttitle = {Training and Test Sets},
	titleaddon = {Google Developers},
	urldate = {2022-09-16},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/H5PM3GUB/splitting-data.html:text/html},
}

@article{noauthor_emnist_2017,
	title = {The {EMNIST} Dataset},
	url = {https://www.nist.gov/itl/products-and-services/emnist-dataset},
	abstract = {What is it? The {EMNIST} dataset is¬†a¬†set of handwritten character digits derived from the},
	journaltitle = {{NIST}},
	urldate = {2022-09-16},
	date = {2017-04-04},
	langid = {english},
	note = {Last Modified: 2019-03-28T09:45-04:00},
	file = {Snapshot:/home/lars/Zotero/storage/N6JMEQTR/emnist-dataset.html:text/html},
}

@online{yann_lecun_mnist_nodate,
	title = {{MNIST} handwritten digit database, Yann {LeCun}, Corinna Cortes and Chris Burges},
	url = {http://yann.lecun.com/exdb/mnist/},
	author = {{Yann LeCun} and {Corinna Cortes} and {Christopher J.C. Burges}},
	urldate = {2022-09-16},
	file = {MNIST handwritten digit database, Yann LeCun, Corinna Cortes and Chris Burges:/home/lars/Zotero/storage/7ED47RKC/mnist.html:text/html},
}

@book{trahasch_31_2020,
	title = {3.1 Einf√ºhrung {\textbar} Menschen Lernen Maschinelles Lernen - {ML}2},
	url = {https://imla.gitlab.io/ml-buch/ml2-buch/3-1-lr-einfuehrung.html},
	abstract = {This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook.},
	author = {{Trahasch} and {Tobias Hagen} and {Tobias Lauer} and {Volker S√§nger} and {Stephan} and {Klaus Dorer}},
	urldate = {2022-09-16},
	date = {2020-08-08},
	file = {Snapshot:/home/lars/Zotero/storage/H39ZJZ5I/3-1-lr-einfuehrung.html:text/html},
}

@online{laurenz_wuttke_was_2021-1,
	title = {Was ist Supervised Learning (√úberwachtes Lernen)?},
	url = {https://datasolut.com/wiki/supervised-learning/},
	abstract = {Supervised Learning im √úberblick: Lernen Sie, was √ºberwachtes Lernen ist und welche Methoden und Beispiele es gibt.},
	titleaddon = {datasolut {GmbH}},
	author = {{Laurenz Wuttke}},
	urldate = {2022-09-16},
	date = {2021-10-13},
	langid = {german},
	file = {Snapshot:/home/lars/Zotero/storage/SBMIQCAZ/supervised-learning.html:text/html},
}

@incollection{spaulding_is_2020,
	title = {Is Human Judgment Necessary? Artificial Intelligence, Algorithmic Governance, and the Law},
	isbn = {978-0-19-006739-7},
	url = {https://doi.org/10.1093/oxfordhb/9780190067397.013.25},
	shorttitle = {Is Human Judgment Necessary?},
	abstract = {This chapter explores the relationship between rapid developments in artificial intelligence ({AI}) and the exercise of human judgment. Human judgment is unavoidably exercised in designing {AI} systems, and yet some of the most consequential forms of judgment are submerged in the formal rigor of algorithmic syntax. Moreover, whether or not one can conclude that the machines running {AI} themselves ‚Äúmake‚Äù judgments in a deep sense, human judgment is increasingly displaced by {AI} as ‚Äúsmart‚Äù machines perform functions that previously required the exercise of human judgment. Even promising {AI} systems designed to enhance human judgment involve subtle forms of displacement. And {AI} systems being developed in areas such as the law have powerful effects on the epistemological terrain in which human judgment occurs. This chapter describes these effects and then offers ethical, political, and legal justifications for a doctrine of non-delegation to preserve the conditions of human judgment in appropriate domains of social and legal action.},
	booktitle = {The Oxford Handbook of Ethics of {AI}},
	publisher = {Oxford University Press},
	author = {Spaulding, Norman W.},
	editor = {Dubber, Markus D. and Pasquale, Frank and Das, Sunit},
	urldate = {2022-09-16},
	date = {2020-07-09},
	doi = {10.1093/oxfordhb/9780190067397.013.25},
	file = {Snapshot:/home/lars/Zotero/storage/CJR2YMZ4/290666019.html:text/html},
}

@online{noauthor_cadmo_2014,
	title = {{CADMO}, Institute of Theoretical Computer Science, Department of Computer Science, {ETH} Z√ºrich},
	url = {https://cadmo.ethz.ch/education/thesis/template.html},
	urldate = {2022-10-07},
	date = {2014-04-08},
	file = {CADMO, Institute of Theoretical Computer Science, Department of Computer Science, ETH Z√ºrich:/home/lars/Zotero/storage/2G77DUZC/template.html:text/html},
}

@online{noauthor_branchenfuhrende_nodate,
	title = {Branchenf√ºhrende Software f√ºr Vektorgrafiken {\textbar} Adobe Illustrator},
	url = {https://www.adobe.com/ch_de/products/illustrator.html},
	abstract = {Alles, was du mit Illustrator zeichnest, kann beliebig verkleinert oder vergr√∂√üert werden ‚Äì vom Smartphone-Display bis zur Plakatwand. Dabei bleibt jedes Detail gestochen scharf. Denn Illustrator-Grafiken basieren auf Vektoren.},
	urldate = {2022-10-07},
	langid = {german},
	file = {Snapshot:/home/lars/Zotero/storage/WTSHVP8N/illustrator.html:text/html},
}

@online{noauthor_matplotlib_nodate,
	title = {Matplotlib ‚Äî Visualization with Python},
	url = {https://matplotlib.org/},
	urldate = {2022-10-07},
	file = {Matplotlib ‚Äî Visualization with Python:/home/lars/Zotero/storage/KL25HF7C/matplotlib.org.html:text/html},
}

@online{noauthor_tensorflow_2015,
	title = {{TensorFlow}},
	url = {https://www.tensorflow.org/},
	abstract = {An end-to-end open source machine learning platform for everyone. Discover {TensorFlow}'s flexible ecosystem of tools, libraries and community resources.},
	urldate = {2022-10-02},
	date = {2015},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/DMATMKGV/www.tensorflow.org.html:text/html},
}

@inreference{noauthor_python_2022,
	title = {Python (Programmiersprache)},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://de.wikipedia.org/w/index.php?title=Python_(Programmiersprache)&oldid=226267434},
	abstract = {Python ([Ààp ∞a…™Œ∏nÃ©], [Ààp ∞a…™Œ∏…ën], auf Deutsch auch [Ààp ∞yÀêt…în]) ist eine universelle, √ºblicherweise interpretierte, h√∂here Programmiersprache. Sie hat den Anspruch, einen gut lesbaren, knappen Programmierstil zu f√∂rdern. So werden beispielsweise Bl√∂cke nicht durch geschweifte Klammern, sondern durch Einr√ºckungen strukturiert.
Python unterst√ºtzt mehrere Programmierparadigmen, z. B. die objektorientierte, die aspektorientierte und die funktionale Programmierung. Ferner bietet es eine dynamische Typisierung. Wie viele dynamische Sprachen wird Python oft als Skriptsprache genutzt. Die Sprache weist ein offenes, gemeinschaftsbasiertes Entwicklungsmodell auf, das durch die gemeinn√ºtzige Python Software Foundation gest√ºtzt wird, die die Definition der Sprache in der Referenzumsetzung {CPython} pflegt.},
	booktitle = {Wikipedia},
	urldate = {2022-10-02},
	date = {2022-09-18},
	langid = {german},
	note = {Page Version {ID}: 226267434},
	file = {Snapshot:/home/lars/Zotero/storage/RYILFPS3/Python_(Programmiersprache).html:text/html},
}

@online{sadie_bennett_why_2019,
	title = {Why machine learning is primarily written in Python},
	url = {https://developer.ibm.com/blogs/why-machine-learning-is-primarily-written-in-python/},
	abstract = {This beginner{\textbackslash}'s blog looks at why machine learning is primarily written in Python.},
	titleaddon = {{IBM} Developer},
	author = {{Sadie Bennett}},
	urldate = {2022-10-02},
	date = {2019-06-10},
	file = {Snapshot:/home/lars/Zotero/storage/5YTCEWH5/why-machine-learning-is-primarily-written-in-python.html:text/html},
}

@online{garnett_bayesian_nodate,
	title = {Bayesian Optimization Book},
	url = {https://bayesoptbook.com//},
	abstract = {Copyright 2021 Roman Garnett, to be published by Cambridge University Press},
	titleaddon = {Bayesian Optimization Book},
	author = {Garnett, Roman},
	urldate = {2022-10-02},
	langid = {american},
	file = {Snapshot:/home/lars/Zotero/storage/NNC8EXQV/bayesoptbook.com.html:text/html},
}

@misc{moriconi_high-dimensional_2020,
	title = {High-dimensional Bayesian optimization using low-dimensional feature spaces},
	url = {http://arxiv.org/abs/1902.10675},
	doi = {10.48550/arXiv.1902.10675},
	abstract = {Bayesian optimization ({BO}) is a powerful approach for seeking the global optimum of expensive black-box functions and has proven successful for fine tuning hyper-parameters of machine learning models. However, {BO} is practically limited to optimizing 10--20 parameters. To scale {BO} to high dimensions, we usually make structural assumptions on the decomposition of the objective and{\textbackslash}slash or exploit the intrinsic lower dimensionality of the problem, e.g. by using linear projections. We could achieve a higher compression rate with nonlinear projections, but learning these nonlinear embeddings typically requires much data. This contradicts the {BO} objective of a relatively small evaluation budget. To address this challenge, we propose to learn a low-dimensional feature space jointly with (a) the response surface and (b) a reconstruction mapping. Our approach allows for optimization of {BO}'s acquisition function in the lower-dimensional subspace, which significantly simplifies the optimization problem. We reconstruct the original parameter space from the lower-dimensional subspace for evaluating the black-box function. For meaningful exploration, we solve a constrained optimization problem.},
	number = {{arXiv}:1902.10675},
	publisher = {{arXiv}},
	author = {Moriconi, Riccardo and Deisenroth, Marc P. and Kumar, K. S. Sesh},
	urldate = {2022-10-02},
	date = {2020-09-25},
	eprinttype = {arxiv},
	eprint = {1902.10675 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/home/lars/Zotero/storage/VSS5ZSIV/Moriconi et al. - 2020 - High-dimensional Bayesian optimization using low-d.pdf:application/pdf;arXiv.org Snapshot:/home/lars/Zotero/storage/4QUVJZYK/1902.html:text/html},
}

@online{robbins_machine_2017,
	title = {{MACHINE} {LEARNING}: How Black is This Beautiful Black Box},
	url = {https://towardsdatascience.com/machine-learning-how-black-is-this-black-box-f11e4031fdf},
	shorttitle = {{MACHINE} {LEARNING}},
	abstract = {Software is much better now than it was a few decades ago. Machine learning is better than it was. The machine learning software libraries‚Ä¶},
	titleaddon = {Medium},
	author = {Robbins, Bruce},
	urldate = {2022-10-02},
	date = {2017-07-14},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/4JR4DIPZ/machine-learning-how-black-is-this-black-box-f11e4031fdf.html:text/html},
}

@article{agnihotri_exploring_2020,
	title = {Exploring Bayesian Optimization},
	volume = {5},
	issn = {2476-0757},
	url = {https://distill.pub/2020/bayesian-optimization},
	doi = {10.23915/distill.00026},
	abstract = {How to tune hyperparameters for your machine learning model using Bayesian optimization.},
	pages = {e26},
	number = {5},
	journaltitle = {Distill},
	shortjournal = {Distill},
	author = {Agnihotri, Apoorv and Batra, Nipun},
	urldate = {2022-10-02},
	date = {2020-05-05},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/FDRCJ75R/bayesian-optimization.html:text/html},
}

@video{machine_learning_mastery_bayesian_2021,
	title = {Bayesian Optimization - Math and Algorithm Explained},
	url = {https://www.youtube.com/watch?v=ECNU4WIuhSE},
	author = {{Machine Learning Mastery}},
	urldate = {2022-10-02},
	date = {2021-05-31},
}

@inreference{noauthor_black_2021,
	title = {Black Box (Systemtheorie)},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://de.wikipedia.org/w/index.php?title=Black_Box_(Systemtheorie)&oldid=215860839},
	abstract = {Als Black Box bezeichnet man in Kybernetik und Systemtheorie ein (m√∂glicherweise sehr komplexes) System, von welchem im gegebenen Zusammenhang nur das √§u√üere Verhalten betrachtet werden soll. Die innere Struktur mag bekannt sein; solche Kenntnis darf aber nicht benutzt werden (etwa weil ein Nachfolgemodell innen anders gebaut sein darf). Man beschr√§nkt sich bei der Untersuchung und Beschreibung auf die Messung der Input-Output-Beziehungen ({EVA}-Prinzip).
Anders als ein geschlossenes System in der Thermodynamik darf so ein System auch Materie mit der Umgebung austauschen, zum Beispiel ein Fahrscheinautomat.
Das Gegenteil einer Black Box wird meistens als White Box (engl. wei√üe Kiste) bezeichnet; die metaphorisch konsistenteren Begriffe Glass Box und Clear Box (englisch Glaskiste bzw. durchsichtige Kiste) sind synonym, werden aber seltener verwendet.},
	booktitle = {Wikipedia},
	urldate = {2022-10-02},
	date = {2021-09-24},
	langid = {german},
	note = {Page Version {ID}: 215860839},
	file = {Snapshot:/home/lars/Zotero/storage/REIMUIH7/Black_Box_(Systemtheorie).html:text/html},
}

@online{nagesh_singh_chauhan_naive_2022,
	title = {Na√Øve Bayes Algorithm: Everything You Need to Know},
	url = {https://www.kdnuggets.com/naive-bayes-algorithm-everything-you-need-to-know.html},
	shorttitle = {Na√Øve Bayes Algorithm},
	abstract = {Na√Øve Bayes is a probabilistic machine learning algorithm based on the¬†Bayes Theorem, used in a wide variety of classification tasks. In this article, we will understand the Na√Øve Bayes algorithm and all essential concepts so that there is no room for doubts in understanding.},
	titleaddon = {{KDnuggets}},
	author = {{Nagesh Singh Chauhan}},
	urldate = {2022-10-02},
	date = {2022-04-08},
	langid = {american},
	note = {Section: {KDnuggets} Republished},
}

@online{noauthor_5_2019,
	title = {5 Git Best Practices For Git Commit},
	url = {https://www.perforce.com/blog/vcs/git-best-practices-git-commit},
	abstract = {Checking in code is an essential step with any version control system. Review our Git commit best practices before you start checking in.},
	titleaddon = {Perforce Software},
	urldate = {2022-10-02},
	date = {2019-11-07},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/5SAQIJ83/git-best-practices-git-commit.html:text/html},
}

@inreference{noauthor_git_2022,
	title = {Git},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://de.wikipedia.org/w/index.php?title=Git&oldid=226360876},
	abstract = {Git […°…™t] ist eine freie Software zur verteilten Versionsverwaltung von Dateien, die durch Linus Torvalds initiiert wurde.},
	booktitle = {Wikipedia},
	urldate = {2022-10-02},
	date = {2022-09-21},
	langid = {german},
	note = {Page Version {ID}: 226360876},
	file = {Snapshot:/home/lars/Zotero/storage/4G4E4ARE/Git.html:text/html},
}

@online{rajendra_koppula_exploration_nodate,
	title = {Exploration vs. Exploitation in Reinforcement Learning},
	url = {https://www.manifold.ai/exploration-vs-exploitation-in-reinforcement-learning},
	abstract = {We simulate the multi-armed bandit problem in order to understand the tradeoff between exploration and exploitation in reinforcement learning.},
	author = {{Rajendra Koppula}},
	urldate = {2022-10-02},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/SGQXTC9W/exploration-vs-exploitation-in-reinforcement-learning.html:text/html},
}

@online{pramoditha_concept_2021,
	title = {The Concept of Artificial Neurons (Perceptrons) in Neural Networks},
	url = {https://towardsdatascience.com/the-concept-of-artificial-neurons-perceptrons-in-neural-networks-fab22249cbfc},
	abstract = {Neural Networks and Deep Learning Course: Part 1},
	titleaddon = {Medium},
	author = {Pramoditha, Rukshan},
	urldate = {2022-10-01},
	date = {2021-12-29},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/DWZ3I6P5/the-concept-of-artificial-neurons-perceptrons-in-neural-networks-fab22249cbfc.html:text/html},
}

@online{atlassian_pull_nodate,
	title = {Pull Requests {\textbar} Atlassian Git Tutorial},
	url = {https://www.atlassian.com/de/git/tutorials/making-a-pull-request},
	abstract = {Mithilfe von Pull-Requests k√∂nnen Entwickler √Ñnderungen √ºber eine benutzerfreundliche Oberfl√§che diskutieren, bevor sie in ein Projekt eingearbeitet werden.},
	titleaddon = {Atlassian},
	author = {Atlassian},
	urldate = {2022-10-01},
	langid = {german},
	file = {Snapshot:/home/lars/Zotero/storage/A3EHVIIX/making-a-pull-request.html:text/html},
}

@online{guillermo_brachetta_what_2022,
	title = {What are Git Branches? \& How They Work},
	url = {https://codeinstitute.net/global/blog/git-branches/},
	shorttitle = {What are Git Branches?},
	abstract = {Git Branches allow us to work on different versions of our code simultaneously. In this blog, we explain what branches are and how they work.},
	titleaddon = {Code Institute Global},
	author = {{Guillermo Brachetta}},
	urldate = {2022-10-01},
	date = {2022-03-03},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/Y63AWPHF/git-branches.html:text/html},
}

@online{atlassian_what_nodate,
	title = {What is version control {\textbar} Atlassian Git Tutorial},
	url = {https://www.atlassian.com/git/tutorials/what-is-version-control},
	abstract = {Version control systems keep track of every change to a file over time so early versions can be restored and are used by software teams for source code},
	titleaddon = {Atlassian},
	author = {Atlassian},
	urldate = {2022-10-01},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/G3WZX2NE/what-is-version-control.html:text/html},
}

@inreference{noauthor_git_2022-1,
	title = {Git},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://de.wikipedia.org/w/index.php?title=Git&oldid=226360876},
	abstract = {Git […°…™t] ist eine freie Software zur verteilten Versionsverwaltung von Dateien, die durch Linus Torvalds initiiert wurde.},
	booktitle = {Wikipedia},
	urldate = {2022-10-01},
	date = {2022-09-21},
	langid = {german},
	note = {Page Version {ID}: 226360876},
	file = {Snapshot:/home/lars/Zotero/storage/F3BAHBTR/Git.html:text/html},
}

@online{atlassian_git-flow-workflow_nodate,
	title = {Git-flow-Workflow {\textbar} Atlassian Git Tutorial},
	url = {https://www.atlassian.com/de/git/tutorials/comparing-workflows/gitflow-workflow},
	abstract = {Ein umfassender Einblick in den Git-flow-Workflow. In diesem umfassenden Tutorial erf√§hrst du, ob dieser Git-Workflow f√ºr dich und dein Team die richtige Wahl ist.},
	titleaddon = {Atlassian},
	author = {Atlassian},
	urldate = {2022-10-07},
	langid = {german},
	file = {Snapshot:/home/lars/Zotero/storage/L7PPDTE9/gitflow-workflow.html:text/html},
}

@online{noauthor_what_2022,
	title = {What is Git Flow {\textbar} How to use Git Flow {\textbar} Learn Git},
	url = {https://www.gitkraken.com/learn/git/git-flow},
	abstract = {Learn about the Git Flow workflow, including what it is, how to use Git flow, and compare it to other Git branching strategies like {GitHub} flow and {GitLab} flow.},
	urldate = {2022-10-07},
	date = {2022-06-17},
	langid = {american},
	note = {Section: Git},
	file = {Snapshot:/home/lars/Zotero/storage/9QI52EFN/git-flow.html:text/html},
}

@online{cameron_mckenzie_gitflow_2021,
	title = {Gitflow release branch process from start to finish example},
	url = {https://www.theserverside.com/blog/Coffee-Talk-Java-News-Stories-and-Opinions/Gitflow-release-branch-process-start-finish},
	author = {{Cameron McKenzie}},
	urldate = {2022-10-07},
	date = {2021-02-24},
	file = {Gitflow release branch process from start to finish example:/home/lars/Zotero/storage/RKSEVK9N/Gitflow-release-branch-process-start-finish.html:text/html},
}

@software{mor_emnist_2022,
	title = {{EMNIST}},
	url = {https://github.com/shubhammor0403/EMNIST},
	abstract = {Classify and predict words using {EMNIST} dataset},
	author = {Mor, Shubham},
	urldate = {2022-10-07},
	date = {2022-06-01},
	note = {original-date: 2018-07-17T12:21:46Z},
}

@online{david_e_rumelhart_learning_nodate,
	title = {Learning representations by back-propagating errors},
	url = {https://www.iro.umontreal.ca/~vincentp/ift3395/lectures/backprop_old.pdf},
	author = {{David E. Rumelhart} and {Geoffrey E. Hinton} and {Ronald J. Williams}},
	urldate = {2022-09-16},
	file = {backprop_old.pdf:/home/lars/Zotero/storage/YNFDR45C/backprop_old.pdf:application/pdf},
}

@software{aleksandra_deis_quick_2022,
	title = {The Quick, Draw! Dataset},
	url = {https://github.com/googlecreativelab/quickdraw-dataset},
	abstract = {Documentation on how to access and use the Quick, Draw! Dataset.},
	publisher = {Google Creative Lab},
	author = {{Aleksandra Deis}},
	urldate = {2022-10-07},
	date = {2022-10-06},
	note = {original-date: 2017-05-09T18:28:32Z},
	keywords = {dataset, quickdraw-dataset},
}

@online{atlassian_git-flow-workflow_nodate-1,
	title = {Git-flow-Workflow {\textbar} Atlassian Git Tutorial},
	url = {https://www.atlassian.com/de/git/tutorials/comparing-workflows/gitflow-workflow},
	abstract = {Ein umfassender Einblick in den Git-flow-Workflow. In diesem umfassenden Tutorial erf√§hrst du, ob dieser Git-Workflow f√ºr dich und dein Team die richtige Wahl ist.},
	titleaddon = {Atlassian},
	author = {Atlassian},
	urldate = {2022-10-08},
	langid = {german},
	file = {Snapshot:/home/lars/Zotero/storage/XVTXDDH4/gitflow-workflow.html:text/html},
}

@online{noauthor_fileblackboxsvg_nodate,
	title = {File:Blackbox.svg - Wikipedia},
	url = {https://commons.wikimedia.org/wiki/File:Blackbox.svg},
	shorttitle = {File},
	urldate = {2022-10-08},
	langid = {italian},
	file = {Snapshot:/home/lars/Zotero/storage/VPWZKW7K/FileBlackbox.html:text/html},
}

@book{trahasch_menschen_2020,
	title = {Menschen Lernen Maschinelles Lernen - {ML}2},
	url = {https://imla.gitlab.io/ml-buch/ml2-buch/index.html},
	abstract = {This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook.},
	author = {Trahasch, Tobias Hagen, Tobias Lauer, Volker S√§nger, Stephan, Klaus Dorer},
	urldate = {2022-10-08},
	date = {2020-08-08},
	file = {Snapshot:/home/lars/Zotero/storage/Q6B2IYBS/index.html:text/html},
}

@misc{mnih_playing_2013,
	title = {Playing Atari with Deep Reinforcement Learning},
	url = {http://arxiv.org/abs/1312.5602},
	doi = {10.48550/arXiv.1312.5602},
	abstract = {We present the first deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We find that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.},
	number = {{arXiv}:1312.5602},
	publisher = {{arXiv}},
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
	urldate = {2022-10-08},
	date = {2013-12-19},
	eprinttype = {arxiv},
	eprint = {1312.5602 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/home/lars/Zotero/storage/UG3K8A62/Mnih et al. - 2013 - Playing Atari with Deep Reinforcement Learning.pdf:application/pdf;arXiv.org Snapshot:/home/lars/Zotero/storage/6L452MNQ/1312.html:text/html},
}

@online{david_e_rumelhart_learning_1985,
	title = {Learning Internal Representations by error propagation},
	url = {https://apps.dtic.mil/dtic/tr/fulltext/u2/a164453.pdf},
	author = {{David E. Rumelhart} and {Geoffrey E. Hinton} and {Ronald J. Williams}},
	urldate = {2022-09-16},
	date = {1985-09},
	file = {a164453.pdf:/home/lars/Zotero/storage/WN5HNYLW/a164453.pdf:application/pdf},
}

@online{roman_garnett_bayesian_nodate,
	title = {Bayesian Optimization},
	url = {https://bayesoptbook.com/book/bayesoptbook.pdf},
	author = {{Roman Garnett}},
	urldate = {2022-10-02},
	file = {bayesoptbook.pdf:/home/lars/Zotero/storage/39ER84YE/bayesoptbook.pdf:application/pdf},
}

@online{aaron_hertzmann_stroke-based_2002,
	title = {Stroke-Based Rendering},
	url = {https://www.cs.ucdavis.edu/~ma/SIGGRAPH02/course23/notes/S02c23_3.pdf},
	abstract = {This chapter describesstroke-based rendering ({SBR}), an automatic approach to creating non-photorealistic imagery by placing discrete elements called strokes, such as paint strokes or stipples. Many strokebased rendering algorithms and styles have been proposed, including styles of painting, pen-and-ink drawing, tile mosaics, stippling, streamline visualization, tensor field visualization and jigsaw image mosaics. This tutorial attemps to make sense of the disparate work in this area by creating a unified view of {SBR} algorithms, which helps us to identify the common elements, as well as the unique ideasof each.},
	author = {{Aaron Hertzmann}},
	urldate = {2022-09-16},
	date = {2002-04-15},
	file = {S02c23_3.pdf:/home/lars/Zotero/storage/AS8EISNR/S02c23_3.pdf:application/pdf},
}

@online{sergey_levine_learning_nodate,
	title = {Learning Dynamical System Models from Data},
	url = {https://rll.berkeley.edu/deeprlcoursesp17/docs/week_3_lecture_1_dynamics_learning.pdf},
	author = {{Sergey Levine}},
	urldate = {2022-03-27},
	file = {week_3_lecture_1_dynamics_learning.pdf:/home/lars/Zotero/storage/KZMIE5FU/week_3_lecture_1_dynamics_learning.pdf:application/pdf},
}

@online{noauthor_keras_2015,
	title = {Keras: the Python deep learning {API}},
	url = {https://keras.io/},
	urldate = {2022-10-09},
	date = {2015},
	file = {Keras\: the Python deep learning API:/home/lars/Zotero/storage/73KVE2DU/keras.io.html:text/html},
}

@misc{cohen_emnist_2017,
	title = {{EMNIST}: an extension of {MNIST} to handwritten letters},
	url = {http://arxiv.org/abs/1702.05373},
	doi = {10.48550/arXiv.1702.05373},
	shorttitle = {{EMNIST}},
	abstract = {The {MNIST} dataset has become a standard benchmark for learning, classification and computer vision systems. Contributing to its widespread adoption are the understandable and intuitive nature of the task, its relatively small size and storage requirements and the accessibility and ease-of-use of the database itself. The {MNIST} database was derived from a larger dataset known as the {NIST} Special Database 19 which contains digits, uppercase and lowercase handwritten letters. This paper introduces a variant of the full {NIST} dataset, which we have called Extended {MNIST} ({EMNIST}), which follows the same conversion paradigm used to create the {MNIST} dataset. The result is a set of datasets that constitute a more challenging classification tasks involving letters and digits, and that shares the same image structure and parameters as the original {MNIST} task, allowing for direct compatibility with all existing classifiers and systems. Benchmark results are presented along with a validation of the conversion process through the comparison of the classification results on converted {NIST} digits and the {MNIST} digits.},
	number = {{arXiv}:1702.05373},
	publisher = {{arXiv}},
	author = {Cohen, Gregory and Afshar, Saeed and Tapson, Jonathan and van Schaik, Andr√©},
	urldate = {2022-10-09},
	date = {2017-02-17},
	eprinttype = {arxiv},
	eprint = {1702.05373 [cs]},
	note = {version: 1},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/lars/Zotero/storage/IAWRSI4E/Cohen et al. - 2017 - EMNIST an extension of MNIST to handwritten lette.pdf:application/pdf;arXiv.org Snapshot:/home/lars/Zotero/storage/TYLPN87N/1702.html:text/html},
}

@online{yann_lecun_papers_nodate,
	title = {Papers with Code - {MNIST} Dataset},
	url = {https://paperswithcode.com/dataset/mnist},
	abstract = {The {MNIST} database (Modified National Institute of Standards and Technology database) is a large collection of handwritten digits. It has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger {NIST} Special Database 3 (digits written by employees of the United States Census Bureau) and Special Database 1 (digits written by high school students) which contain monochrome images of handwritten digits. The digits have been size-normalized and centered in a fixed-size image. The original black and white (bilevel) images from {NIST} were size normalized to fit in a 20x20 pixel box while preserving their aspect ratio. The resulting images contain grey levels as a result of the anti-aliasing technique used by the normalization algorithm. the images were centered in a 28x28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field.},
	author = {{Yann LeCun}},
	urldate = {2022-10-09},
	langid = {english},
	file = {Snapshot:/home/lars/Zotero/storage/SIKRJNPJ/mnist.html:text/html},
}